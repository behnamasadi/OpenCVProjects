{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09f7ec2-55da-43b2-a238-aa08ee45256c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Taylor of a function around point a:\n",
    "First lets review some math:\n",
    "<br/>\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?f%28x%29%3Df%28a%29&plus;f%27%28a%29%28x-a%29&plus;%5Cfrac%7B1%7D%7B2%7D%28x-a%29f%27%27%28a%29%28x-a%29&plus;%5Cfrac%7B1%7D%7B6%7Df%27%27%27%28a%29%28x-a%29%5E3&plus;...\" alt=\"https://latex.codecogs.com/svg.latex?f(x)=f(a)+f'(a)(x-a)+\\frac{1}{2}(x-a)f''(a)(x-a)+\\frac{1}{6}f'''(a)(x-a)^3+...\" />\n",
    "\n",
    "\n",
    "If we substitute\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?x%20%3D%20a&plus;%5CDelta%20x\" alt=\"https://latex.codecogs.com/svg.latex?x = a+\\Delta x\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5C%5C%20f%28x%29%20%3D%20f%28a&plus;%5CDelta%20x%29%20%3D%20f%28a%29%20&plus;%20f%5E%7B%27%7D%28a%29%28a%20&plus;%20%5CDelta%20x-a%29%20&plus;%20%5Cfrac%7Bf%5E%7B%27%27%7D%28a%29%28a%20&plus;%20%5CDelta%20x-a%29%5E2%7D%7B2%21%7D%20&plus;%20%5Ctext%7B...%7D%20%5C%5C%20%3D%20f%28a%29%20&plus;f%5E%7B%27%7D%28a%29%5CDelta%20x&plus;%20%5Cfrac%7Bf%5E%7B%27%27%7D%28a%29%7D%7B2%21%7D%28%5CDelta%20x%29%5E2%20&plus;%20%5Ctext%7B...%7D\" alt=\"https://latex.codecogs.com/svg.latex?\\\\\n",
    "f(x) = f(a+\\Delta x) = f(a) + f^{'}(a)(a + \\Delta x-a) + \\frac{f^{''}(a)(a + \\Delta x-a)^2}{2!} + \\text{...}\n",
    "\\\\\n",
    "= f(a) +f^{'}(a)\\Delta x+ \\frac{f^{''}(a)}{2!}(\\Delta x)^2 + \\text{...}\" />\n",
    "\n",
    "\n",
    "\n",
    "## Multivariable Taylor \n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cbegin%7Balign*%7D%20p_2%28x%2Cy%29%20%26%3D%20f%28a%2Cb%29%20&plus;%20D%20f%28a%2Cb%29_%7B1%5Ctimes2%7D%20%5Cleft%5B%20%5Cbegin%7Barray%7D%7Bc%7D%20x-a%20%5C%5C%20y-b%20%5Cend%7Barray%7D%20%5Cright%5D%20&plus;%20%5Cfrac%7Ba%7D%7B2%7D%20%5Cleft%5B%20%5Cbegin%7Barray%7D%7Bcc%7D%20x-a%20%26y-b%20%5Cend%7Barray%7D%20%5Cright%5D%20Hf%28a%2Cb%29_%7B2%5Ctimes2%7D%20%5Cleft%5B%20%5Cbegin%7Barray%7D%7Bc%7D%20x-a%20%5C%5C%20y-b%20%5Cend%7Barray%7D%20%5Cright%5D%20%5Cend%7Balign*%7D\" alt=\"https://latex.codecogs.com/svg.latex?\\begin{align*}   p_2(x,y) &= f(a,b) +  D f(a,b)_{1\\times2}   \\left[     \\begin{array}{c}       x-a \\\\ y-b     \\end{array}   \\right]   + \\frac{a}{2}   \\left[     \\begin{array}{cc}       x-a &y-b      \\end{array}   \\right]   Hf(a,b)_{2\\times2}    \\left[     \\begin{array}{c}       x-a \\\\ y-b     \\end{array}   \\right]\n",
    "\\end{align*}\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## Optical Flow\n",
    "\n",
    "Between two image frames which are taken at times <img src=\"https://latex.codecogs.com/svg.latex?t\" alt=\"https://latex.codecogs.com/svg.latex?t\" /> and  <img src=\"https://latex.codecogs.com/svg.latex?t&plus;%5CDelta%20t\" alt=\"https://latex.codecogs.com/svg.latex?t+\\Delta t\" /> at every position following brightness constancy constraint:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?I%28x%2Cy%2Ct%29%20%3D%20I%28x&plus;%5CDelta%20x%2C%20y%20&plus;%20%5CDelta%20y%2C%20t%20&plus;%20%5CDelta%20t%29\" alt=\"https://latex.codecogs.com/svg.latex?I(x,y,t) = I(x+\\Delta x, y + \\Delta y, t + \\Delta t)\" />\n",
    "\n",
    "\n",
    "\n",
    "Assuming the movement to be small, Taylor series of:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?I%28x&plus;%5CDelta%20x%2C%20y%20&plus;%20%5CDelta%20y%2C%20t%20&plus;%20%5CDelta%20t%29\" alt=\"https://latex.codecogs.com/svg.latex?I(x+\\Delta x, y + \\Delta y, t + \\Delta t)\" /> \n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "is:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20I%28x&plus;%5CDelta%20x%2Cy&plus;%5CDelta%20y%2Ct&plus;%5CDelta%20t%29%3DI%28x%2Cy%2Ct%29&plus;%7B%5Cfrac%20%7B%5Cpartial%20I%7D%7B%5Cpartial%20x%7D%7D%5C%2C%5CDelta%20x&plus;%7B%5Cfrac%20%7B%5Cpartial%20I%7D%7B%5Cpartial%20y%7D%7D%5C%2C%5CDelta%20y&plus;%7B%5Cfrac%20%7B%5Cpartial%20I%7D%7B%5Cpartial%20t%7D%7D%5C%2C%5CDelta%20t&plus;%7B%7D%7D%20%5Ctext%7Bhigher-order%20terms%7D\" alt=\"https://latex.codecogs.com/svg.latex?{\\displaystyle I(x+\\Delta x,y+\\Delta y,t+\\Delta t)=I(x,y,t)+{\\frac {\\partial I}{\\partial x}}\\,\\Delta x+{\\frac {\\partial I}{\\partial y}}\\,\\Delta y+{\\frac {\\partial I}{\\partial t}}\\,\\Delta t+{}} \\text{higher-order terms}\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cfrac%7B%5Cpartial%20I%7D%7B%5Cpartial%20x%7D%5CDelta%20x&plus;%5Cfrac%7B%5Cpartial%20I%7D%7B%5Cpartial%20y%7D%5CDelta%20y&plus;%5Cfrac%7B%5Cpartial%20I%7D%7B%5Cpartial%20t%7D%5CDelta%20t%20%3D%200\" alt=\"https://latex.codecogs.com/svg.latex?\\frac{\\partial I}{\\partial x}\\Delta x+\\frac{\\partial I}{\\partial y}\\Delta y+\\frac{\\partial I}{\\partial t}\\Delta t = 0\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "dividing by <img src=\"https://latex.codecogs.com/svg.latex?%5CDelta%20t\" alt=\"https://latex.codecogs.com/svg.latex?\\Delta t\" />:\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20%7B%5Cfrac%20%7B%5Cpartial%20I%7D%7B%5Cpartial%20x%7D%7D%7B%5Cfrac%20%7B%5CDelta%20x%7D%7B%5CDelta%20t%7D%7D&plus;%7B%5Cfrac%20%7B%5Cpartial%20I%7D%7B%5Cpartial%20y%7D%7D%7B%5Cfrac%20%7B%5CDelta%20y%7D%7B%5CDelta%20t%7D%7D&plus;%7B%5Cfrac%20%7B%5Cpartial%20I%7D%7B%5Cpartial%20t%7D%7D%7B%5Cfrac%20%7B%5CDelta%20t%7D%7B%5CDelta%20t%7D%7D%3D0%7D\" alt=\"https://latex.codecogs.com/svg.latex?{\\displaystyle {\\frac {\\partial I}{\\partial x}}{\\frac {\\Delta x}{\\Delta t}}+{\\frac {\\partial I}{\\partial y}}{\\frac {\\Delta y}{\\Delta t}}+{\\frac {\\partial I}{\\partial t}}{\\frac {\\Delta t}{\\Delta t}}=0}\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cfrac%7B%5Cpartial%20I%7D%7B%5Cpartial%20x%7DV_x&plus;%5Cfrac%7B%5Cpartial%20I%7D%7B%5Cpartial%20y%7DV_y&plus;%5Cfrac%7B%5Cpartial%20I%7D%7B%5Cpartial%20t%7D%20%3D%200\" alt=\"https://latex.codecogs.com/svg.latex?\\frac{\\partial I}{\\partial x}V_x+\\frac{\\partial I}{\\partial y}V_y+\\frac{\\partial I}{\\partial t} = 0\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?I_xV_x&plus;I_yV_y%3D-I_t\" alt=\"https://latex.codecogs.com/svg.latex?I_xV_x+I_yV_y=-I_t\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20%5Cnabla%20I%5Ccdot%20%7B%5Cvec%20%7BV%7D%7D%3D-I_%7Bt%7D%7D\" alt=\"https://latex.codecogs.com/svg.latex?{\\displaystyle \\nabla I\\cdot {\\vec {V}}=-I_{t}}\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## Aperture Problem\n",
    "\n",
    "This equation: \n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20%5Cnabla%20I%5Ccdot%20%7B%5Cvec%20%7BV%7D%7D%3D-I_%7Bt%7D%7D\" alt=\"https://latex.codecogs.com/svg.latex?{\\displaystyle \\nabla I\\cdot {\\vec {V}}=-I_{t}}\" />\n",
    "\n",
    "\n",
    "is known as the aperture problem of the optical flow, has two unknowns.  To find the optical flow another set of equations is needed, given by some additional constraint. All optical flow methods introduce additional conditions for estimating the actual flow.\n",
    "\n",
    "## Lucas-Kanade Method\n",
    "\n",
    "Lucas-Kanade method takes a `3x3` patch around the point. So all the 9 points have the same motion. So now our problem becomes solving 9 equations with two unknown variables which is over-determined.\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20%7B%5Cbegin%7Baligned%7DI_%7Bx%7D%28q_%7B1%7D%29V_%7Bx%7D&plus;I_%7By%7D%28q_%7B1%7D%29V_%7By%7D%26%3D-I_%7Bt%7D%28q_%7B1%7D%29%5C%5CI_%7Bx%7D%28q_%7B2%7D%29V_%7Bx%7D&plus;I_%7By%7D%28q_%7B2%7D%29V_%7By%7D%26%3D-I_%7Bt%7D%28q_%7B2%7D%29%5C%5C%26%5C%3B%5C%20%5Cvdots%20%5C%5CI_%7Bx%7D%28q_%7Bn%7D%29V_%7Bx%7D&plus;I_%7By%7D%28q_%7Bn%7D%29V_%7By%7D%26%3D-I_%7Bt%7D%28q_%7Bn%7D%29%5Cend%7Baligned%7D%7D%7D\" alt=\"https://latex.codecogs.com/svg.latex?{\\displaystyle {\\begin{aligned}I_{x}(q_{1})V_{x}+I_{y}(q_{1})V_{y}&=-I_{t}(q_{1})\\\\I_{x}(q_{2})V_{x}+I_{y}(q_{2})V_{y}&=-I_{t}(q_{2})\\\\&\\;\\ \\vdots \\\\I_{x}(q_{n})V_{x}+I_{y}(q_{n})V_{y}&=-I_{t}(q_{n})\\end{aligned}}}\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?Av%3Db\" alt=\"https://latex.codecogs.com/svg.latex?Av=b\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20A%3D%7B%5Cbegin%7Bbmatrix%7DI_%7Bx%7D%28q_%7B1%7D%29%26I_%7By%7D%28q_%7B1%7D%29%5C%5C%5B10pt%5DI_%7Bx%7D%28q_%7B2%7D%29%26I_%7By%7D%28q_%7B2%7D%29%5C%5C%5B10pt%5D%5Cvdots%20%26%5Cvdots%20%5C%5C%5B10pt%5DI_%7Bx%7D%28q_%7Bn%7D%29%26I_%7By%7D%28q_%7Bn%7D%29%5Cend%7Bbmatrix%7D%7D%5Cquad%20%5Cquad%20%5Cquad%20v%3D%7B%5Cbegin%7Bbmatrix%7DV_%7Bx%7D%5C%5C%5B10pt%5DV_%7By%7D%5Cend%7Bbmatrix%7D%7D%5Cquad%20%5Cquad%20%5Cquad%20b%3D%7B%5Cbegin%7Bbmatrix%7D-I_%7Bt%7D%28q_%7B1%7D%29%5C%5C%5B10pt%5D-I_%7Bt%7D%28q_%7B2%7D%29%5C%5C%5B10pt%5D%5Cvdots%20%5C%5C%5B10pt%5D-I_%7Bt%7D%28q_%7Bn%7D%29%5Cend%7Bbmatrix%7D%7D%7D\" alt=\"https://latex.codecogs.com/svg.latex?{\\displaystyle A={\\begin{bmatrix}I_{x}(q_{1})&I_{y}(q_{1})\\\\[10pt]I_{x}(q_{2})&I_{y}(q_{2})\\\\[10pt]\\vdots &\\vdots \\\\[10pt]I_{x}(q_{n})&I_{y}(q_{n})\\end{bmatrix}}\\quad \\quad \\quad v={\\begin{bmatrix}V_{x}\\\\[10pt]V_{y}\\end{bmatrix}}\\quad \\quad \\quad b={\\begin{bmatrix}-I_{t}(q_{1})\\\\[10pt]-I_{t}(q_{2})\\\\[10pt]\\vdots \\\\[10pt]-I_{t}(q_{n})\\end{bmatrix}}}\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "to solve this problem:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5C%5C%20%7B%5Cdisplaystyle%20A%5E%7BT%7DAv%3DA%5E%7BT%7Db%7D%5C%5C%20%5C%5C%20%7B%5Cdisplaystyle%20%5Cmathrm%20%7Bv%7D%20%3D%28A%5E%7BT%7DA%29%5E%7B-1%7DA%5E%7BT%7Db%7D\" alt=\"https://latex.codecogs.com/svg.latex?\\\\\n",
    "{\\displaystyle A^{T}Av=A^{T}b}\\\\\n",
    "\\\\\n",
    "{\\displaystyle \\mathrm {v} =(A^{T}A)^{-1}A^{T}b}\" />\n",
    "\n",
    "\n",
    "\n",
    "That is, it computes\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5Cdisplaystyle%20%7B%5Cbegin%7Bbmatrix%7DV_%7Bx%7D%5C%5C%5B10pt%5DV_%7By%7D%5Cend%7Bbmatrix%7D%7D%3D%7B%5Cbegin%7Bbmatrix%7D%5Csum%20_%7Bi%7DI_%7Bx%7D%28q_%7Bi%7D%29%5E%7B2%7D%26%5Csum%20_%7Bi%7DI_%7Bx%7D%28q_%7Bi%7D%29I_%7By%7D%28q_%7Bi%7D%29%5C%5C%5B10pt%5D%5Csum%20_%7Bi%7DI_%7By%7D%28q_%7Bi%7D%29I_%7Bx%7D%28q_%7Bi%7D%29%26%5Csum%20_%7Bi%7DI_%7By%7D%28q_%7Bi%7D%29%5E%7B2%7D%5Cend%7Bbmatrix%7D%7D%5E%7B-1%7D%7B%5Cbegin%7Bbmatrix%7D-%5Csum%20_%7Bi%7DI_%7Bx%7D%28q_%7Bi%7D%29I_%7Bt%7D%28q_%7Bi%7D%29%5C%5C%5B10pt%5D-%5Csum%20_%7Bi%7DI_%7By%7D%28q_%7Bi%7D%29I_%7Bt%7D%28q_%7Bi%7D%29%5Cend%7Bbmatrix%7D%7D%7D\" alt=\"https://latex.codecogs.com/svg.latex?{\\displaystyle {\\begin{bmatrix}V_{x}\\\\[10pt]V_{y}\\end{bmatrix}}={\\begin{bmatrix}\\sum _{i}I_{x}(q_{i})^{2}&\\sum _{i}I_{x}(q_{i})I_{y}(q_{i})\\\\[10pt]\\sum _{i}I_{y}(q_{i})I_{x}(q_{i})&\\sum _{i}I_{y}(q_{i})^{2}\\end{bmatrix}}^{-1}{\\begin{bmatrix}-\\sum _{i}I_{x}(q_{i})I_{t}(q_{i})\\\\[10pt]-\\sum _{i}I_{y}(q_{i})I_{t}(q_{i})\\end{bmatrix}}}\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "# OpenCV OpticalFlow API\n",
    "\n",
    "## SparseOpticalFlow \n",
    "Abstract base class for calculating sparse optical-flow.\n",
    "\n",
    "## SparsePyrLKOpticalFlow\n",
    "\n",
    "`buildOpticalFlowPyramid`: Constructs the image pyramid which can be passed to `calcOpticalFlowPyrLK`\n",
    "\n",
    "<img src=\"images/Pyramid_Level_0.png\" />\n",
    "<br/>  \n",
    "<img src=\"images/Pyramid_Level_1.png\" />  \n",
    "<br/>  \n",
    "<img src=\"images/Pyramid_Level_2.png\" />  \n",
    "<br/>  \n",
    "<img src=\"images/Pyramid_Level_3.png\" />  \n",
    "\n",
    "\n",
    "```\n",
    "ret, pyramid = cv2.buildOpticalFlowPyramid(\n",
    "    img, winSize, maxLevel, withDerivatives=False, pyrBorder=cv2.BORDER_REFLECT)\n",
    "```\n",
    "\n",
    "`withDerivatives`:set to precompute gradients for the every pyramid level. If pyramid is constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The class can calculate an optical flow for a sparse feature set using the iterative Lucas-Kanade method with pyramids.\n",
    "\n",
    "\n",
    "- `nextPts`: output vector of 2D points (floating-point coordinates) containing the calculated new positions of input features in the second image;\n",
    "when OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.\n",
    "\n",
    "\n",
    "- `status`: output status vector (of unsigned chars); each element of the vector is set to 1\n",
    "if the flow for the corresponding features has been found, otherwise, it is set to 0.\n",
    "\n",
    "\n",
    "- `err`: output vector of errors; each element of the vector is set to an error for the corresponding feature,\n",
    "type of the error measure can be set in flags parameter; if the flow wasn't found then the error is not defined (use the status parameter to find such cases).\n",
    "\n",
    "- `maxLevel`: 0-based maximal pyramid level number; if set to 0, pyramids are not used (single level), if set to 1, two levels are used, and so on;\n",
    "if pyramids are passed to input then algorithm will use as many levels as pyramids have but no more than maxLevel.\n",
    "\n",
    "\n",
    "Refs: [1](https://github.com/npinto/opencv/blob/master/samples/python2/lk_track.py), [2](https://github.com/npinto/opencv/blob/master/samples/python2/lk_homography.py)\n",
    "\n",
    "## DenseOpticalFlow\n",
    "Abstract base class for calculating dense optical-flow.\n",
    "\n",
    "### FarnebackOpticalFlow \n",
    "Farnebäck Optical Flow (`cv2.FarnebackOpticalFlow_create()`):\n",
    "\n",
    "Algorithm developed by Gunnar Farnebäck.\n",
    "Based on polynomial expansion to approximate neighboring pixel displacements.\n",
    "Typically faster than more recent methods, but may not be as accurate for complex scenes or large displacements.\n",
    "Good compromise between accuracy and speed for real-time applications.\n",
    "\n",
    "### DualTVL1OpticalFlow\n",
    "\n",
    "Dual TV L1 Optical Flow (`cv2.DualTVL1OpticalFlow_create()`):\n",
    "\n",
    "Based on the Total Variation (TV) regularization, which tends to produce cleaner flow fields.\n",
    "Often provides smoother and more coherent flow than Farnebäck, but at the cost of computational efficiency.\n",
    "Can handle larger displacements than Farnebäck.\n",
    "Has several parameters that can be tweaked, which may require tuning for specific applications.\n",
    "\n",
    "### DenseOpticalFlow\n",
    "DeepFlow (`cv2.optflow.createOptFlow_DeepFlow()`):\n",
    "\n",
    "Uses smoothness assumptions as in classical methods but also takes advantage of descriptor matching, which can be seen as a regularized, dense version of sparse matching techniques.\n",
    "Generally provides high-quality results but can be slower.\n",
    "\n",
    "### SimpleFlow\n",
    "SimpleFlow (`cv2.optflow.createOptFlow_SimpleFlow()`):\n",
    "\n",
    "Designed to be a more straightforward, non-regularized version of the DeepFlow algorithm.\n",
    "It might be faster than DeepFlow but could provide less accurate results due to the absence of regularization.\n",
    "\n",
    "### PCA-Flow, PCA-Layers, and SPARSE-PCA\n",
    "\n",
    "PCA-Flow, PCA-Layers, and SPARSE-PCA (`cv2.optflow.createOptFlow_PCAFlow()` and related methods):\n",
    "\n",
    "Uses principal component analysis to compute optical flow.\n",
    "Tends to be experimental and might be better suited for specific scenes or scenarios.\n",
    "\n",
    "### DIS Optical Flow\n",
    "DIS Optical Flow (`cv2.optflow.createOptFlow_DIS()`):\n",
    "\n",
    "Stands for Dense Inverse Search.\n",
    "Designed to be faster and more efficient, especially with parallel processing capabilities.\n",
    "Provides competitive accuracy with other state-of-the-art methods but with faster performance.\n",
    "\n",
    "\n",
    "\n",
    "Each of these algorithms has its strengths and weaknesses, and the choice depends on the application's specific requirements, such as computational efficiency, accuracy, and the nature of the video sequences.\n",
    "\n",
    "For a comparative analysis tailored to a particular scenario or application, one would typically evaluate each method on sample data to measure factors like accuracy, computational time, robustness to noise, and visual quality of the flow fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d00b7-1964-489c-bf96-a892dfd4a39d",
   "metadata": {},
   "source": [
    "# DIS Optical Flow\n",
    "Stands for Dense Inverse Search.\n",
    "\n",
    "```python\n",
    "dis = cv2.DISOpticalFlow_create()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = dis.calc(prev_frame_gray, frame_gray, None)\n",
    "\n",
    "    # Visualization of the flow\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    hsv[..., 1] = 255\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow(\"Optical Flow\", bgr)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('', frame_gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    prev_frame = frame_gray.copy()\n",
    "```\n",
    "\n",
    "\n",
    "1. **Initialization of the HSV Image**:\n",
    "   ```python\n",
    "   hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "   ```\n",
    "   Here, a new image `hsv` is being initialized to have the same dimensions as the computed `flow` image. The image is of type HSV (Hue, Saturation, Value), and hence it has 3 channels. All pixels are initialized to zero.\n",
    "\n",
    "2. **Setting Saturation to Maximum**:\n",
    "   ```python\n",
    "   hsv[..., 1] = 255\n",
    "   ```\n",
    "   The saturation channel of the HSV image is set to the maximum value of 255. This is done to make the output color as vibrant as possible, which makes the visualization of the flow vectors more apparent.\n",
    "\n",
    "3. **Converting Cartesian to Polar**:\n",
    "   ```python\n",
    "   mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "   ```\n",
    "   The `flow` image contains horizontal and vertical displacement values. This can be thought of as Cartesian coordinates. `cv2.cartToPolar` converts these Cartesian coordinates into polar coordinates, providing the magnitude (`mag`) and angle (`ang`) of the flow vectors. \n",
    "\n",
    "4. **Setting the Hue Based on Flow Direction**:\n",
    "   ```python\n",
    "   hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "   ```\n",
    "   The angle (`ang`) is in radians, ranging from \\(0\\) to \\(2\\pi\\). This line of code converts the angle to degrees (using `180/np.pi`) and then scales it to fit within the range of the Hue channel in the HSV color space, which is typically from 0 to 180.\n",
    "\n",
    "5. **Setting the Value Based on Flow Magnitude**:\n",
    "   ```python\n",
    "   hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "   ```\n",
    "   The magnitude of the flow is normalized to fit within the range of the Value channel in the HSV color space, which is from 0 to 255. The normalization ensures that small and large flow magnitudes get mapped to the full range of available brightness values.\n",
    "\n",
    "To summarize:\n",
    "- The **Hue** channel represents the direction of the motion (angle of the flow vector).\n",
    "- The **Saturation** channel is kept at maximum to ensure vibrant colors.\n",
    "- The **Value** channel represents the magnitude of the motion (length of the flow vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7b0fe-44fb-43cb-93cb-87f5bc7f2f3b",
   "metadata": {},
   "source": [
    "This class, `App`, is designed to track features in a video stream using the Lucas-Kanade method of optical flow. Here's a breakdown of the class and its functionality:\n",
    "\n",
    "#### Initialization (`__init__` method):\n",
    "\n",
    "1. **Attributes**:\n",
    "    - `self.track_len`: Specifies the maximum length for a track. A track will store this many previous positions of a feature.\n",
    "    - `self.detect_interval`: The interval at which new features are detected. If set to 1, it means that new features are detected in every frame.\n",
    "    - `self.tracks`: A list that will store the tracks (sequences of positions) of the features being tracked.\n",
    "    - `self.cam`: Initializes a video capture object. Here, it's set to capture from the default camera (`cv2.VideoCapture(0)`).\n",
    "    - `self.frame_idx`: An index counter for the frames being processed.\n",
    "\n",
    "#### Running the App (`run` method):\n",
    "\n",
    "1. **Capture Frames**:\n",
    "    The `while` loop continuously captures frames from the video source:\n",
    "    ```python\n",
    "    ret, frame = self.cam.read()\n",
    "    ```\n",
    "\n",
    "2. **Convert to Grayscale**:\n",
    "    To process optical flow, it's typically done on grayscale images:\n",
    "    ```python\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ```\n",
    "\n",
    "3. **Visualization Setup**:\n",
    "    A copy of the original frame is made for visualization purposes:\n",
    "    ```python\n",
    "    vis = frame.copy()\n",
    "    ```\n",
    "\n",
    "4. **Display Track Information** (Optional Debugging):\n",
    "    If there are tracks available, print information about the length of the first track and the total number of tracks:\n",
    "    ```python\n",
    "    if (len(self.tracks) > 0):\n",
    "        print(\"self.tracks[0]\\n\", len(self.tracks[0]))\n",
    "        print(\"------------------------------------\")\n",
    "        print(\"self.tracks\\n\", len(self.tracks))\n",
    "    ```\n",
    "\n",
    "5. **Feature Tracking with Lucas-Kanade**:\n",
    "    If there are feature tracks available, the code calculates the new positions of these features in the current frame using optical flow:\n",
    "    \n",
    "    - The previous frame (`self.prev_gray`) and the current frame (`frame_gray`) are used to estimate the new positions (`p1`) of the features.\n",
    "    \n",
    "    - A backward flow is also calculated from the current to the previous frame to ensure the accuracy of the feature tracking.\n",
    "    \n",
    "    - The difference between the forward and backward optical flow (`d`) is computed to identify and discard poor matches.\n",
    "    \n",
    "    - Only the good tracks are then updated and visualized.\n",
    "\n",
    "6. **Feature Detection**:\n",
    "    At regular intervals (determined by `self.detect_interval`), new features are detected in the frame to be tracked:\n",
    "    \n",
    "    - A mask is created such that existing features are ignored. This ensures that the newly detected features are not too close to the already tracked ones.\n",
    "    \n",
    "    - The detected features are added to the `self.tracks` list for tracking.\n",
    "\n",
    "7. **Update the Frame Counter and Display the Result**:\n",
    "    The frame index is incremented, the current frame is saved as `self.prev_gray`, and the visualization frame (`vis`) is displayed using `cv2.imshow`.\n",
    "\n",
    "8. **Handle User Input**:\n",
    "    The code waits for a short interval to detect any key press by the user. If the `Esc` key (ASCII value 27) is pressed, the loop breaks and the application exits.\n",
    "\n",
    "This class, when instantiated and run, essentially provides a visual demonstration of feature tracking using optical flow in real-time on video captured from the default camera.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This code block updates the list of tracked feature points based on the optical flow estimation. Let's break it down step by step:\n",
    "\n",
    "1. **Loop through the tracks, calculated points, and good flags**:\n",
    "    ```python\n",
    "    for tr, (x, y), good_flag in zip(self.tracks, p1.reshape(-1, 2), good):\n",
    "    ```\n",
    "    - `zip` is used to iterate over multiple lists simultaneously.\n",
    "    - `tr` represents a track from `self.tracks`, which is a list of points indicating the path of a feature over a number of frames.\n",
    "    - `(x, y)` represents the new position of the tracked feature after estimating the optical flow.\n",
    "    - `good_flag` is a boolean value indicating whether the optical flow estimation for this point is valid or not.\n",
    "\n",
    "2. **Check for good flag**:\n",
    "    ```python\n",
    "    if not good_flag:\n",
    "        continue\n",
    "    ```\n",
    "    If the optical flow estimation is not valid for the current feature point (`good_flag` is `False`), then we skip the rest of the loop for this feature.\n",
    "\n",
    "3. **Update the track**:\n",
    "    ```python\n",
    "    tr.append((x, y))\n",
    "    ```\n",
    "    Add the new point `(x, y)` to the end of the current track.\n",
    "\n",
    "4. **Limit track length**:\n",
    "    ```python\n",
    "    if len(tr) > self.track_len:\n",
    "        del tr[0]\n",
    "    ```\n",
    "    Ensure that the track doesn't exceed a predefined length (`self.track_len`). If it does, remove the oldest point.\n",
    "\n",
    "5. **Add track to new_tracks**:\n",
    "    ```python\n",
    "    new_tracks.append(tr)\n",
    "    ```\n",
    "    Add the updated track to the `new_tracks` list.\n",
    "\n",
    "6. **Draw the new point**:\n",
    "    ```python\n",
    "    cv2.circle(vis, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "    ```\n",
    "    Draw a green circle (`(0, 255, 0)`) of radius 2 at the new point `(x, y)` on the visualization frame (`vis`).\n",
    "\n",
    "7. **Update the tracks list**:\n",
    "    ```python\n",
    "    self.tracks = new_tracks\n",
    "    ```\n",
    "    After processing all the tracks, assign `new_tracks` to `self.tracks`.\n",
    "\n",
    "8. **Draw tracks**:\n",
    "    ```python\n",
    "    cv2.polylines(vis, [np.int32(tr) for tr in self.tracks], False, (0, 255, 0))\n",
    "    ```\n",
    "    Draw the paths of the tracked features in green on the visualization frame. Each track is represented as a polyline.\n",
    "\n",
    "9. **Display the number of tracks**:\n",
    "    ```python\n",
    "    cv2.putText(vis, 'track count: %d' % len(self.tracks), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    ```\n",
    "    Display the number of active tracks on the visualization frame at the coordinates `(20, 20)` with the specified font, size, and color.\n",
    "\n",
    "In summary, this code block updates the tracked feature points based on the optical flow estimations, prunes invalid or old tracks, and visualizes the tracking results on a frame.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This block of code is used to detect new feature points in the current frame at regular intervals (as defined by `self.detect_interval`). The points are then added to the list of points (`self.tracks`) that are being tracked across frames. Here's a step-by-step breakdown:\n",
    "\n",
    "1. **Conditional Check**:\n",
    "    ```python\n",
    "    if self.frame_idx % self.detect_interval == 0:\n",
    "    ```\n",
    "    As explained previously, this condition checks if it's the right frame to detect new features based on the set interval (`self.detect_interval`).\n",
    "\n",
    "2. **Initialize Mask**:\n",
    "    ```python\n",
    "    mask = np.zeros_like(frame_gray)\n",
    "    mask[:] = 255\n",
    "    ```\n",
    "    A mask of the same size as `frame_gray` (the grayscale version of the current frame) is created and initialized to all white (255).\n",
    "\n",
    "3. **Mask Current Tracks**:\n",
    "    ```python\n",
    "    for x, y in [np.int32(tr[-1]) for tr in self.tracks]:\n",
    "        cv2.circle(mask, (x, y), 5, 0, -1)\n",
    "    ```\n",
    "    For each track in `self.tracks`, the most recent point (`tr[-1]`) is considered. A black circle (pixel value `0`) of radius `5` is drawn on the white mask at this point's location. This effectively masks out areas around the currently tracked points to prevent the detection of new features too close to the existing ones.\n",
    "\n",
    "4. **Detect Good Features to Track**:\n",
    "    ```python\n",
    "    p = cv2.goodFeaturesToTrack(frame_gray, mask=mask, **feature_params)\n",
    "    ```\n",
    "    `cv2.goodFeaturesToTrack()` is a function in OpenCV that detects corners using the Shi-Tomasi method (similar to Harris corner detection). Here, it's applied to `frame_gray` (the current frame in grayscale) using the mask created earlier, ensuring that new features are detected in areas not already covered by existing tracks. The function uses the parameters specified in `feature_params`.\n",
    "\n",
    "5. **Add Detected Features to Tracks**:\n",
    "    ```python\n",
    "    if p is not None:\n",
    "        for x, y in np.float32(p).reshape(-1, 2):\n",
    "            self.tracks.append([(x, y)])\n",
    "    ```\n",
    "    If the detection function found any good features (`p is not None`), each of these detected points is appended to `self.tracks` for further tracking in subsequent frames.\n",
    "\n",
    "In essence, this block of code ensures that at regular intervals, new feature points are detected and added to the list of tracked points, replenishing it as some might get lost or move out of frame over time.\n",
    "\n",
    "\n",
    "\n",
    "Certainly! Let's break down the line:\n",
    "\n",
    "```python\n",
    "if self.frame_idx % self.detect_interval == 0:\n",
    "```\n",
    "\n",
    "1. **self.frame_idx**: \n",
    "    - Represents the index or count of the frames being processed. It starts from `0` and is incremented for every frame that the program processes.\n",
    "    \n",
    "2. **self.detect_interval**:\n",
    "    - A predetermined interval that specifies how often the program should detect new feature points to track. For instance, if `self.detect_interval` is set to `5`, then new feature points would be detected every 5 frames.\n",
    "    \n",
    "3. **self.frame_idx % self.detect_interval**: \n",
    "    - This is the modulo operation. It computes the remainder when `self.frame_idx` is divided by `self.detect_interval`.\n",
    "    \n",
    "4. **self.frame_idx % self.detect_interval == 0**: \n",
    "    - This condition checks if the remainder of the above division is `0`. If it is, then `self.frame_idx` is a multiple of `self.detect_interval`.\n",
    "\n",
    "Putting it all together, this line checks if the current frame index (`self.frame_idx`) is an exact multiple of the specified detection interval (`self.detect_interval`). If the condition is `True`, the code inside the `if` block is executed. \n",
    "\n",
    "In the context of the code, this means that every `self.detect_interval` frames, the program detects new feature points to add to the tracking list. This is useful to keep replenishing tracked points as some might get lost or move out of the frame over time.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Certainly! This line of code is part of a forward-backward error check used in the Lucas-Kanade method of optical flow.\n",
    "\n",
    "Here's the line in question:\n",
    "\n",
    "```python\n",
    "d = abs(p0-p0r).reshape(-1, 2).max(-1)\n",
    "```\n",
    "\n",
    "Let's break it down step by step:\n",
    "\n",
    "1. **Forward-Backward Optical Flow**:\n",
    "    - `p0`: The original set of point coordinates in the first image.\n",
    "    - `p1`: The estimated positions of those points in the second image after applying forward optical flow using `cv2.calcOpticalFlowPyrLK()`.\n",
    "    - `p0r`: The estimated positions of the `p1` points when mapped back to the first image using reverse optical flow.\n",
    "\n",
    "2. **Difference Calculation**:\n",
    "    - `p0-p0r`: This calculates the difference between the original positions of the points and the positions obtained after forward and then backward tracking (i.e., the error in the backtracked position compared to the original position).\n",
    "\n",
    "3. **Reshaping**:\n",
    "    - `.reshape(-1, 2)`: This reshapes the difference array such that it has two columns, one for the x-coordinates and the other for the y-coordinates.\n",
    "\n",
    "4. **Maximum Difference**:\n",
    "    - `.max(-1)`: This computes the maximum difference for each point across the x and y coordinates. The `-1` for the `axis` parameter indicates that the maximum should be computed along the last axis (which in this case is axis 1, the columns). So, for each point, you get the maximum of the absolute differences in x and y directions.\n",
    "\n",
    "The result `d` is an array where each element represents the maximum error (either in x or y) for the corresponding point after doing a forward-backward optical flow tracking. It essentially gives a measure of the tracking's reliability: if the error is high, it means the point probably wasn't tracked accurately.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
