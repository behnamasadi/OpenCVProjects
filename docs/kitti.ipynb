{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60b1fbd-ac67-4f1e-a91f-6bcf6bfd6671",
   "metadata": {},
   "source": [
    "# Dataset Visual Odometry / SLAM Evaluation\n",
    "\n",
    "1. [Download odometry data set (grayscale, 22 GB)](https://s3.eu-central-1.amazonaws.com/avg-kitti/data_odometry_gray.zip)\n",
    "2. [Download odometry data set (color, 65 GB)](https://s3.eu-central-1.amazonaws.com/avg-kitti/data_odometry_color.zip)\n",
    "3. [Download odometry data set (velodyne laser data, 80 GB)](https://s3.eu-central-1.amazonaws.com/avg-kitti/data_odometry_velodyne.zip)\n",
    "4. [Download odometry data set (calibration files, 1 MB)](https://s3.eu-central-1.amazonaws.com/avg-kitti/data_odometry_calib.zip)\n",
    "5. [Download odometry ground truth poses (4 MB)](https://s3.eu-central-1.amazonaws.com/avg-kitti/data_odometry_poses.zip)\n",
    "\n",
    "\n",
    "\n",
    "# Sensor setup \n",
    "<img src=\"images/setup_top_view.png\" />\n",
    "\n",
    "<img src=\"images/passat_sensors_920.png\" />\n",
    "\n",
    "\n",
    "\n",
    "- $P0$: Reference camera (left of stereo pair 1), extrinsics are identity.\n",
    "- $P1$: Right camera of stereo pair 1, extrinsics include baseline offset.\n",
    "- $P2$: Left camera of stereo pair 2, extrinsics depend on setup.\n",
    "- $P3$: Right camera of stereo pair 2, extrinsics depend on setup.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Camera: $P0$:\n",
    "\n",
    "```\n",
    "Projection Matrix:\n",
    "[[707.0912   0.     601.8873   0.    ]\n",
    " [  0.     707.0912 183.1104   0.    ]\n",
    " [  0.       0.       1.       0.    ]]\n",
    "Intrinsic Matrix:\n",
    "[[707.0912   0.     601.8873]\n",
    " [  0.     707.0912 183.1104]\n",
    " [  0.       0.       1.    ]]\n",
    "Rotation Matrix:\n",
    "[[1. 0. 0.]\n",
    " [0. 1. 0.]\n",
    " [0. 0. 1.]]\n",
    "Translation Vector:\n",
    "[[0.]\n",
    " [0.]\n",
    " [0.]]\n",
    "```\n",
    "---\n",
    "\n",
    "Camera: $P1$:\n",
    "```\n",
    "Projection Matrix:\n",
    "[[ 707.0912    0.      601.8873 -379.8145]\n",
    " [   0.      707.0912  183.1104    0.    ]\n",
    " [   0.        0.        1.        0.    ]]\n",
    "Intrinsic Matrix:\n",
    "[[707.0912   0.     601.8873]\n",
    " [  0.     707.0912 183.1104]\n",
    " [  0.       0.       1.    ]]\n",
    "Rotation Matrix:\n",
    "[[1. 0. 0.]\n",
    " [0. 1. 0.]\n",
    " [0. 0. 1.]]\n",
    "Translation Vector:\n",
    "[[ 5.37150653e-01]\n",
    " [-1.34802944e-17]\n",
    " [ 0.00000000e+00]]\n",
    "```\n",
    "\n",
    "From the above image the distance between two camera is `0.54` on $x$ axis and from decomposition we have: `5.37150653e-01`.\n",
    "\n",
    "Refs: [1](https://www.cvlibs.net/datasets/kitti/setup.php)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837648a-40ce-4d67-8e0e-7e8054279907",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Refs: [1](https://stackoverflow.com/questions/29407474/how-to-understand-the-kitti-camera-calibration-files), [2](https://github.com/yanii/kitti-pcl/blob/master/KITTI_README.TXT), [3](https://www.cvlibs.net/datasets/kitti/eval_odometry.php), [4](https://github.com/avisingh599/mono-vo/)\n",
    "\n",
    "\n",
    "\n",
    "Refs: [1](https://rpg.ifi.uzh.ch/docs/VO_Part_I_Scaramuzza.pdf), [2](https://rpg.ifi.uzh.ch/docs/VO_Part_II_Scaramuzza.pdf), [3](https://rpg.ifi.uzh.ch/docs/Visual_Odometry_Tutorial.pdf), [4](https://github.com/alishobeiri/Monocular-Video-Odometery), [5](https://avisingh599.github.io/vision/monocular-vo/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71705b1a-2cd5-4af1-afe5-02d8df2ae9e0",
   "metadata": {},
   "source": [
    "\n",
    "# Ground Truth Poses\n",
    "each row of the data has 12 columns, 12 come from flattening a `3x4` transformation matrix of the left:\n",
    "\n",
    "```\n",
    "r11 r12 r13 tx r21 r22 r23 ty r31 r32 r33 tz\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655e3c3-5ce8-42b8-a7c1-610f4a5665cf",
   "metadata": {},
   "source": [
    "## Reconstruct Sparse/Dense Model From Known Camera Poses with Colmap\n",
    "\n",
    "Your data should have the following structure: \n",
    "\n",
    "```\n",
    "├── database.db\n",
    "├── dense\n",
    "│   └── sparse\n",
    "│       └── model\n",
    "│           └── 0\n",
    "├── images\n",
    "│   ├── 00000.png\n",
    "│   ├── 00001.png\n",
    "│   ├── 00002.png\n",
    "│   └── 00003.png\n",
    "└── sparse\n",
    "    └── model\n",
    "        └── 0\n",
    "            ├── cameras.txt\n",
    "            ├── images.txt\n",
    "            └── points3D.txt\n",
    "```\n",
    "\n",
    "1. `cameras.txt`: should be like this:\n",
    "\n",
    "```\n",
    "# Camera list with one line of data per camera:\n",
    "#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]\n",
    "# Number of cameras: 3\n",
    "1 SIMPLE_PINHOLE 3072 2304 2559.81 1536 1152\n",
    "2 PINHOLE 3072 2304 2560.56 2560.56 1536 1152\n",
    "3 SIMPLE_RADIAL 3072 2304 2559.69 1536 1152 -0.0218531\n",
    "```\n",
    "\n",
    "2. `images.txt`: should be like this:\n",
    "\n",
    "```\n",
    "# Image list with two lines of data per image:\n",
    "#   IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n",
    "#   POINTS2D[] as (X, Y, POINT3D_ID)\n",
    "# Number of images: 2, mean observations per image: 2\n",
    "1 0.695104 0.718385 -0.024566 0.012285 -0.046895 0.005253 -0.199664 1 00000.png\n",
    "\n",
    "2 0.696445 0.717090 -0.023185 0.014441 -0.041213 0.001928 -0.134851 1 00001.png\n",
    "\n",
    "3 0.697457 0.715925 -0.025383 0.018967 -0.054056 0.008579 -0.378221 1 00002.png\n",
    "\n",
    "4 0.698777 0.714625 -0.023996 0.021129 -0.048184 0.004529 -0.313427 1 00003.png\n",
    "```\n",
    "and finally:\n",
    "\n",
    "3. `points3D.txt`: This file should be empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90c5bc-e993-401f-8afa-db235f99593c",
   "metadata": {},
   "source": [
    "KITI format for ground truth poses (for instance, for the file `data/kitti/odometry/05/poses/05.txt`) is:\n",
    "\n",
    "```\n",
    "# r11 r12 r13 tx r21 r22 r23 ty r31 r32 r33 tz\n",
    "```\n",
    "The colmap format for `images.txt` is: \n",
    "\n",
    "```\n",
    "# colmap format:\n",
    "# IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n",
    "```\n",
    "\n",
    "Run the script [kitti_to_colmap.py](../scripts/kitti/kitti_to_colmap.py). It dumps the output into `images.txt` file. \n",
    "\n",
    "\n",
    "You can run the following script to add noise:\n",
    "\n",
    "```\n",
    "[kitti_to_colmap_noise](../scripts/kitti/kitti_to_colmap_noise.py).\n",
    "```\n",
    "\n",
    "The inside of `~/colmap_projects/kitti_noisy` create a soft link pointing to KITTI images:\n",
    "ln -s <path-to-kiti-odometry-image> images\n",
    "\n",
    "in my case:\n",
    "\n",
    "```\n",
    " ln -s /home/$USER/workspace/OpenCVProjects/data/kitti/odometry/05/image_0/ images\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9013dd7-dc63-4c5f-81dd-44affb14862c",
   "metadata": {},
   "source": [
    "### Setting up parameters\n",
    "\n",
    "Then set the camera param:\n",
    "\n",
    "```\n",
    "CAM=707.0912,707.0912,601.8873,183.1104\n",
    "```\n",
    "\n",
    "set the project:\n",
    "```\n",
    "project_name=kitti_noisy\n",
    "DATASET_PATH=/home/$USER/colmap_projects/$project_name\n",
    "```\n",
    "\n",
    "### Feature extraction\n",
    "\n",
    "extract the features:\n",
    "```\n",
    "colmap feature_extractor  \\\n",
    "--database_path $DATASET_PATH/database.db  \\\n",
    "--image_path $DATASET_PATH/images  \\\n",
    "--ImageReader.single_camera=true --ImageReader.camera_model=PINHOLE --ImageReader.camera_params=$CAM \\\n",
    "--SiftExtraction.use_gpu 1 \\\n",
    "--SiftExtraction.estimate_affine_shape=true \\\n",
    "--SiftExtraction.domain_size_pooling=true\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```\n",
    "colmap feature_extractor  \\\n",
    "--database_path $DATASET_PATH/database.db  \\\n",
    "--image_path $DATASET_PATH/images  \\\n",
    "--ImageReader.single_camera=true --ImageReader.camera_model=PINHOLE --ImageReader.camera_params=$CAM\n",
    "```\n",
    "\n",
    "### Matcher\n",
    "run the matcher:\n",
    "\n",
    "```\n",
    "colmap sequential_matcher \\\n",
    "   --database_path $DATASET_PATH/database.db \\\n",
    "   --SequentialMatching.overlap=3 \\\n",
    "   --SequentialMatching.loop_detection=true \\\n",
    "   --SequentialMatching.loop_detection_period=2 \\\n",
    "   --SequentialMatching.loop_detection_num_images=50 \\\n",
    "   --SequentialMatching.vocab_tree_path=\"$DATASET_PATH/../vocab_tree/vocab_tree_flickr100K_words256K.bin\" \\\n",
    "   --SiftMatching.use_gpu 1 --SiftMatching.gpu_index=-1  --SiftMatching.guided_matching=true \n",
    "```\n",
    "\n",
    "Create the following directory:\n",
    "\n",
    "```\n",
    "dense/sparse/model/0\n",
    "dense/refined/model/0\n",
    "```\n",
    "\n",
    "### Triangulation\n",
    "then run the \n",
    "\n",
    "```\n",
    "colmap point_triangulator \\\n",
    "    --database_path $DATASET_PATH/database.db \\\n",
    "    --image_path $DATASET_PATH/images\\\n",
    "    --input_path $DATASET_PATH/sparse/model/0 \\\n",
    "    --output_path $DATASET_PATH/dense/sparse/model/0\n",
    "```\n",
    "\n",
    "Now run bundle adjuster to only optimize the extrinsic (camera position and orientations) and **NOT** intrinsic (camera parameter)\n",
    "\n",
    "\n",
    "```\n",
    "colmap bundle_adjuster  \\\n",
    "  --input_path $DATASET_PATH/dense/sparse/model/0 \\\n",
    "  --output_path $DATASET_PATH/dense/refined/model/0 \\\n",
    "  --BundleAdjustment.refine_focal_length  0 \\\n",
    "  --BundleAdjustment.refine_principal_point   0 \\\n",
    "  --BundleAdjustment.refine_extra_params  0 \\\n",
    "  --BundleAdjustment.refine_extrinsics  1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d5a47-aa10-43c8-887e-52dffdb55791",
   "metadata": {},
   "source": [
    "Refs [1](https://colmap.github.io/faq.html#reconstruct-sparse-dense-model-from-known-camera-poses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
