{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee82b28-28d8-4675-9fcb-34ac27178f03",
   "metadata": {},
   "source": [
    "# Stereo Calibration\n",
    "\n",
    "The following API computes the Poses of an object relative to the first camera: \n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?R_1%2CT_1%20%3D%20R_w%5Ec%2C%20T_w%5Ec\" alt=\"https://latex.codecogs.com/svg.latex?R_1,T_1 = R_w^c, T_w^c\" />\n",
    "\n",
    "\n",
    "Poses of an object relative to the second camera:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?R_2%2CT_2%20%3D%20R2_w%5Ec%2C%20T2_w%5Ec\" alt=\"https://latex.codecogs.com/svg.latex?R_2,T_2 = R2_w^c, T2_w^c\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "It computes <img src=\"https://latex.codecogs.com/svg.latex?R%2CT\" alt=\"https://latex.codecogs.com/svg.latex?R,T\" /> such that:\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5C%5C%20R_2%3DR%20R_1%20%5C%5C%20T_2%3DR%20T_1%20&plus;%20T.\" alt=\"https://latex.codecogs.com/svg.latex?\\\\\n",
    "R_2=R R_1\n",
    "\\\\\n",
    "T_2=R T_1 + T.\" />\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cbegin%7Bbmatrix%7D%20X_2%20%5C%5C%20Y_2%20%5C%5C%20Z_2%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%20R%20%26%20T%20%5C%5C%200%20%26%201%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20X_1%20%5C%5C%20Y_1%20%5C%5C%20Z_1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D.\" alt=\"https://latex.codecogs.com/svg.latex?\\begin{bmatrix} X_2 \\\\ Y_2 \\\\ Z_2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} R & T \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} X_1 \\\\ Y_1 \\\\ Z_1 \\\\ 1 \\end{bmatrix}.\" />\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5C%5C%20E%3D%5Cbegin%7Bbmatrix%7D%200%20%26%20-T_2%20%26T_1%20%5C%5C%20T_2%20%26%200%20%26%20-T_0%5C%5C%20-T_1%20%26%20-T_0%20%26%200%20%5Cend%7Bbmatrix%7D%20%5C%5C%20%5C%5C%20%5C%5C%20T%3D%20%5Cbegin%7Bbmatrix%7D%20T_0%5C%5C%20T_1%5C%5C%20T_2%20%5Cend%7Bbmatrix%7D\" alt=\"https://latex.codecogs.com/svg.latex?\\\\\n",
    "E=\\begin{bmatrix}\n",
    "0 & -T_2 &T_1 \\\\ \n",
    "T_2 & 0 & -T_0\\\\ \n",
    "-T_1 & -T_0 & 0\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "T=\n",
    "\\begin{bmatrix}\n",
    "T_0\\\\ \n",
    "T_1\\\\ \n",
    "T_2\n",
    "\\end{bmatrix}\n",
    "\" />\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?F%20%3D%20cameraMatrix2%5E%7B-T%7D%5Ccdot%20E%20%5Ccdot%20cameraMatrix1%5E%7B-1%7D\" alt=\"https://latex.codecogs.com/svg.latex?F = cameraMatrix2^{-T}\\cdot E \\cdot cameraMatrix1^{-1}\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "```cpp\n",
    "cv::stereoCalibrate\t(\tInputArrayOfArrays \tobjectPoints,\n",
    "InputArrayOfArrays \timagePoints1,\n",
    "InputArrayOfArrays \timagePoints2,\n",
    "InputOutputArray \tcameraMatrix1,\n",
    "InputOutputArray \tdistCoeffs1,\n",
    "InputOutputArray \tcameraMatrix2,\n",
    "InputOutputArray \tdistCoeffs2,\n",
    "Size \timageSize,\n",
    "InputOutputArray \tR,\n",
    "InputOutputArray \tT,\n",
    "OutputArray \tE,\n",
    "OutputArray \tF,\n",
    "OutputArray \tperViewErrors,\n",
    "int \tflags = CALIB_FIX_INTRINSIC,\n",
    "TermCriteria \tcriteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6) \n",
    ")\t\t\n",
    "```\n",
    "Refs: [1](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga3207604e4b1a1758aa66acb6ed5aa65d)\n",
    "\n",
    "Refs: [1](https://www.cs.cmu.edu/~16385/s17/Slides/13.1_Stereo_Rectification.pdf), [3](https://www.allaboutvision.com/eye-care/measure-pupillary-distance/), [4](https://www.mathworks.com/matlabcentral/answers/1451509-what-should-be-the-distance-between-the-two-cameras)\n",
    "\n",
    "# Stereo Rectification\n",
    "If cameras are calibrated:\n",
    "```cpp\n",
    "cv::stereoRectify\t(\tInputArray \tcameraMatrix1,\n",
    "InputArray \tdistCoeffs1,\n",
    "InputArray \tcameraMatrix2,\n",
    "InputArray \tdistCoeffs2,\n",
    "Size \timageSize,\n",
    "InputArray \tR,\n",
    "InputArray \tT,\n",
    "OutputArray \tR1,\n",
    "OutputArray \tR2,\n",
    "OutputArray \tP1,\n",
    "OutputArray \tP2,\n",
    "OutputArray \tQ,\n",
    "int \tflags = CALIB_ZERO_DISPARITY,\n",
    "double \talpha = -1,\n",
    "Size \tnewImageSize = Size(),\n",
    "Rect * \tvalidPixROI1 = 0,\n",
    "Rect * \tvalidPixROI2 = 0 \n",
    ")\t\t\n",
    "```\n",
    "\n",
    "Refs: [1](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga617b1685d4059c6040827800e72ad2b6)\n",
    "\n",
    "If cameras are not calibrated:\n",
    "```cpp\n",
    "cv::stereoRectifyUncalibrated\t(\tInputArray \tpoints1,\n",
    "InputArray \tpoints2,\n",
    "InputArray \tF,\n",
    "Size \timgSize,\n",
    "OutputArray \tH1,\n",
    "OutputArray \tH2,\n",
    "double \tthreshold = 5 \n",
    ")\t\t\n",
    "```\n",
    "\n",
    "Refs: [1](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#gaadc5b14471ddc004939471339294f052)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Distance Between the two cameras and stereo angle\n",
    "Refs: [1](https://ch.mathworks.com/matlabcentral/answers/1451509-what-should-be-the-distance-between-the-two-cameras#answer_786164), [2](https://correlated.kayako.com/article/78-lens-selection-and-stereo-angle#:~:text=For%20shorter%20focal%20length%20lenses,a%2025%20degree%20stereo%20angle)\n",
    "\n",
    "\n",
    "\n",
    "# Stereo Camera Simulation:\n",
    "\n",
    "### 1. `cv2.stereoCalibrate`\n",
    "\n",
    "This function performs stereo calibration. It estimates the parameters of two cameras and how they relate to each other. Here's what each parameter and return value represents:\n",
    "\n",
    "- **Input Parameters**:\n",
    "  - `objectPoints`: 3D points in the real world. These are typically corners of a chessboard or similar calibration pattern, observed in multiple images.\n",
    "  - `all_imagePoints_cam0`: 2D points in the first camera's image plane corresponding to `objectPoints`.\n",
    "  - `all_imagePoints_cam1`: 2D points in the second camera's image plane corresponding to `objectPoints`.\n",
    "  - `cameraMatrix`: The intrinsic camera matrix for the initial guess of both cameras (assumed to be the same here).\n",
    "  - `distCoeffs`: The distortion coefficients for the initial guess of both cameras (assumed to be the same here).\n",
    "  - `imageSize`: Size of the image used for calibration.\n",
    "\n",
    "- **Return Values**:\n",
    "  - `retval`: A boolean flag indicating if the calibration was successful.\n",
    "  - `cameraMatrix1`, `cameraMatrix2`: Optimized intrinsic camera matrices for each camera.\n",
    "  - `distCoeffs1`, `distCoeffs2`: Optimized distortion coefficients for each camera.\n",
    "  - `R`: Rotation matrix describing the rotation from the first to the second camera.\n",
    "  - `T`: Translation vector describing the translation from the first to the second camera.\n",
    "  - `E`: Essential matrix.\n",
    "  - `F`: Fundamental matrix.\n",
    "\n",
    "The essential matrix (`E`) relates corresponding points in stereo images considering the internal parameters of the cameras, while the fundamental matrix (`F`) relates these points without considering internal parameters.\n",
    "\n",
    "### 2. `cv2.stereoRectify`\n",
    "\n",
    "This function is used to compute the rotation matrices for each camera that bring the corresponding points into the same line, facilitating easier computation of disparity:\n",
    "\n",
    "- **Input Parameters**:\n",
    "  - `cameraMatrix1`, `cameraMatrix2`: Intrinsic parameters of each camera obtained from stereo calibration.\n",
    "  - `distCoeffs1`, `distCoeffs2`: Distortion coefficients of each camera.\n",
    "  - `imageSize`: Size of the image.\n",
    "  - `R`, `T`: Rotation matrix and translation vector obtained from stereo calibration.\n",
    "  - `flags`, `alpha`: Additional parameters to control the rectification process.\n",
    "\n",
    "- **Return Values**:\n",
    "  - `R1`, `R2`: Rectification transforms (rotation matrices) for each camera.\n",
    "  - `P1`, `P2`: Projection matrices in the new (rectified) coordinate systems for each camera.\n",
    "  - `Q`: Disparity-to-depth mapping matrix.\n",
    "  - `validPixROI1`, `validPixROI2`: Valid pixel ROI (Region Of Interest) within the rectified images for each camera.\n",
    "\n",
    "### 3. `cv2.initUndistortRectifyMap`\n",
    "\n",
    "This function computes the undistortion and rectification transformation map for each camera:\n",
    "\n",
    "- **Input Parameters for Each Camera**:\n",
    "  - `cameraMatrix`, `distCoeffs`: Intrinsic parameters and distortion coefficients of the camera.\n",
    "  - `R\n",
    "\n",
    "`: The rectification transform (rotation matrix) obtained from `cv2.stereoRectify`.\n",
    "  - `P`: The projection matrix in the new (rectified) coordinate system for the camera.\n",
    "  - `imageSize`: Size of the image.\n",
    "  - `cv2.CV_16SC2`: Specifies the type of the map to be returned, which is a 16-bit signed two-channel image.\n",
    "\n",
    "- **Return Values for Each Camera**:\n",
    "  - `map1x`, `map1y` (for the first camera): The x and y pixel coordinate remapping arrays. These are used to perform the undistortion and rectification transformation.\n",
    "  - `map2x`, `map2y` (for the second camera): Similarly, the x and y pixel coordinate remapping arrays for the second camera.\n",
    "\n",
    "In essence, the process works as follows:\n",
    "\n",
    "1. **Stereo Calibration (`cv2.stereoCalibrate`)**: Determine the relationship between the two cameras (their relative position and orientation) and refine the individual intrinsic parameters of each camera.\n",
    "\n",
    "2. **Stereo Rectification (`cv2.stereoRectify`)**: Compute the rectification transformations. After rectification, the epipolar lines in stereo images are aligned horizontally, which is essential for stereo correspondence and depth estimation algorithms.\n",
    "\n",
    "3. **Undistort and Rectify Map Creation (`cv2.initUndistortRectifyMap`)**: Generate maps to efficiently rectify and undistort images captured from each camera. These maps are used to transform the captured images into a common plane, aligning them so that corresponding points in the stereo images are on the same row.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To obtain the 3D position of points from a stereo camera setup, you typically follow these steps after setting up and calibrating your stereo cameras:\n",
    "\n",
    "1. **Capture Stereo Images**: Capture images from both the left and right cameras simultaneously.\n",
    "\n",
    "2. **Rectify the Images**: Use the rectification maps (`map1x`, `map1y`, `map2x`, `map2y`) obtained from `cv2.initUndistortRectifyMap` to rectify the images from both cameras. This aligns the images such that their corresponding epipolar lines become co-planar and horizontal.\n",
    "\n",
    "3. **Compute Disparity Map**: Use a stereo matching algorithm like Block Matching to compute the disparity map. The disparity map indicates the pixel distance between corresponding points in the left and right rectified images.\n",
    "\n",
    "4. **Calculate 3D Coordinates**: Once you have the disparity map, you can calculate the 3D coordinates of each point using the disparity-to-depth mapping matrix (`Q`) obtained from `cv2.stereoRectify`.\n",
    "\n",
    "Here's a simplified outline of how this can be done in code, using OpenCV functions:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already captured or loaded rectified images\n",
    "left_image_rectified = cv2.remap(left_image, map1x, map1y, cv2.INTER_LINEAR)\n",
    "right_image_rectified = cv2.remap(right_image, map2x, map2y, cv2.INTER_LINEAR)\n",
    "\n",
    "# Create a stereo matcher object\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "\n",
    "# Compute the disparity map\n",
    "disparity = stereo.compute(left_image_rectified, right_image_rectified)\n",
    "\n",
    "# Normalize the disparity map (for visualization)\n",
    "disparity_visual = cv2.normalize(disparity, None, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX)\n",
    "disparity_visual = np.uint8(disparity_visual)\n",
    "\n",
    "# Compute the 3D points\n",
    "points_3D = cv2.reprojectImageTo3D(disparity, Q)\n",
    "\n",
    "# Filter points based on disparity map\n",
    "mask = disparity > disparity.min()\n",
    "points_3D = points_3D[mask]\n",
    "\n",
    "# Now, points_3D contains the 3D coordinates of the points\n",
    "```\n",
    "\n",
    "### Important Considerations:\n",
    "- **Disparity Map**: The disparity map obtained from block matching represents the differences in horizontal coordinates of corresponding points in the left and right rectified images. It's crucial for calculating depth.\n",
    "  \n",
    "- **Depth Calculation**: The `cv2.reprojectImageTo3D` function transforms the disparity map into a 3D representation. The resulting array (`points_3\n",
    "\n",
    "D`) contains the 3D coordinates (X, Y, Z) of each pixel in the stereo image pair. The Z value represents the depth information.\n",
    "\n",
    "- **Quality of Disparity Map**: The accuracy of the 3D reconstruction heavily depends on the quality of the disparity map. Factors like the number of disparities, block size, and the uniqueness and texture of the scene can affect this.\n",
    "\n",
    "- **Filtering and Masking**: It's common to apply a mask to the disparity map to filter out unreliable values. For example, disparity values that are too small might correspond to infinite distances and are typically not reliable.\n",
    "\n",
    "- **Normalization for Visualization**: The disparity map is often normalized for visualization purposes. This doesn't affect the 3D reconstruction but makes it easier to analyze the disparity visually.\n",
    "\n",
    "- **Camera Calibration and Rectification**: This process assumes that the stereo camera system is well-calibrated and the images are correctly rectified. Errors in calibration or rectification can lead to inaccuracies in the 3D reconstruction.\n",
    "\n",
    "### Final Note:\n",
    "The 3D positions obtained this way are in the coordinate system of the cameras. To interpret these positions in a real-world context, you may need to consider additional transformations, especially if you're integrating this data with other spatial data or sensors.\n",
    "\n",
    "Refs: [1](https://towardsdatascience.com/a-comprehensive-tutorial-on-stereo-geometry-and-stereo-rectification-with-python-7f368b09924a), [2](https://people.scs.carleton.ca/~c_shu/Courses/comp4900d/notes/rectification.pdf), [3](https://www.cs.cmu.edu/~16385/s17/Slides/13.1_Stereo_Rectification.pdf), [4](https://www.andreasjakl.com/understand-and-apply-stereo-rectification-for-depth-maps-part-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4bd75-8e2b-4b24-bbfa-86435412504a",
   "metadata": {},
   "source": [
    "# Stereo Calibration\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "\t<td>\n",
    "\t\t<img src=\"images/Left_Image.png\" width=\"75%\" height=\"75%\" />\n",
    "\t</td>\n",
    "\t<td>\n",
    "\t\t<img src=\"images/Right_Image.png\" width=\"75%\" height=\"75%\" />\n",
    "\t</td>\n",
    "<tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```phyton\n",
    "retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F = cv2.stereoCalibrate(\n",
    "    objectPoints, all_imagePoints_cam0, all_imagePoints_cam1, cameraMatrix, distCoeffs, cameraMatrix, distCoeffs, imageSize)\n",
    "```\n",
    "\n",
    "[code](../scripts/multi_snapshot_stereo.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000a16e-324f-477f-97db-755b8288aac2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"images/stereo_depth.jpg\" width=\"50%\" height=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf2e24-c244-49d5-850c-a16ff3853b33",
   "metadata": {},
   "source": [
    "# Image Rectification\n",
    "Image rectification is transforming an image of a scene into a view that is aligned with a desired coordinate system. The goal of rectification is to remove the effects of camera perspective, rotation, and lens distortion, so that the resulting image has a uniform scale and appears to be captured from a front-facing perspective. \n",
    "\n",
    "\n",
    "In the following:\n",
    " \n",
    "- The camera rotating around the `z` axis.\n",
    "- The virtual image plane at `5°` degree is red and at `90°` is green. \n",
    "- The rectified images are in the blue virtual image plane. \n",
    "- The virtual plane must be parallel to the stereo baseline (orange). \n",
    "\n",
    "\n",
    "|   |   |\n",
    "|---|---|\n",
    "|<img src=\"images/image_rectification_1.png\" alt=\"\" />    |<img src=\"images/image_rectification_8.png\" alt=\"\" />  |\n",
    "|<img src=\"images/image_rectification_20.png\" alt=\"\" />   | <img src=\"images/image_rectification_30.png\" alt=\"\" />  |\n",
    "\n",
    "\n",
    "# Image Rectification Algorithms\n",
    "All rectified images satisfy the following two properties:\n",
    "- All epipolar lines are parallel to the horizontal axis.\n",
    "- Corresponding points have identical vertical coordinates.\n",
    "\n",
    "## Projective rectification\n",
    "Projective rectification is the process of transforming an image so that all parallel lines in the image are transformed to be parallel in the new image. The goal of projective rectification is to obtain a view of the scene that is orthographic or fronto-parallel. Projective rectification can be performed using a homography matrix, which maps points from one image to the other.\n",
    "\n",
    "```\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the two images\n",
    "img1 = cv2.imread('img1.jpg')\n",
    "img2 = cv2.imread('img2.jpg')\n",
    "\n",
    "# Find the homography matrix using the findHomography function\n",
    "homography, _ = cv2.findHomography(src_points, dst_points)\n",
    "\n",
    "# Use the perspectiveTransform function to project the second image onto the first image\n",
    "img2_rectified = cv2.warpPerspective(img2, homography, (img1.shape[1], img1.shape[0]))\n",
    "\n",
    "# Show the rectified images\n",
    "cv2.imshow(\"Rectified Image 1\", img1)\n",
    "cv2.imshow(\"Rectified Image 2\", img2_rectified)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "\n",
    "## Epipolar Rectification\n",
    "Epipolar rectification, on the other hand, is the process of rectifying two images such that the epipolar lines in the two images are aligned. The epipolar lines are the lines that intersect the two images and correspond to a single 3D point in the scene. The goal of epipolar rectification is to simplify the problem of finding corresponding points in two images, as the epipolar lines provide a unique constraint on the corresponding points.\n",
    "\n",
    "\n",
    "##  Computing The Rectification Matrices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A simple way to rectify the two images is to first rotate both cameras so that they are\n",
    "looking perpendicular to the line joining the camera centers c 0 and c 1 . Since there is a de-\n",
    "gree of freedom in the tilt, the smallest rotations that achieve this should be used. Next, to\n",
    "determine the desired twist around the optical axes, make the up vector (the camera y axis)\n",
    "\n",
    "\n",
    "[code](../scripts/image_rectification.py)\n",
    "\n",
    "Refs [1](https://en.wikipedia.org/wiki/Image_rectification), [2](https://www.cs.cmu.edu/~16385/s17/Slides/13.1_Stereo_Rectification.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
