{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1bb46a-50c2-41c3-829a-6293764b7775",
   "metadata": {},
   "source": [
    "# 1. Lenses Distortion\n",
    "\n",
    "## 1.1 Radial Distortions\n",
    "\n",
    "The lens isn't a perfect pinhole, which has the side consequence of causing symmetric radial distortion. Outside of the perspective center, light enters the lens and bends toward the image plane. The best way to understand symmetric radial distortion could be to imagine that the concavity or convexity of the lens is being used to map the image plane. Because all light passes through a single point in a pinhole camera, there would be no distortion.\n",
    "\n",
    "\n",
    "Because it solely models distortion as a function of distance from the center of the image plane, this distortion is described as being symmetric. Radial distortion only has a geometric impact in the radial direction,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1.1 Pincushion Distortion (Positive Radial Distortions)\n",
    "\n",
    "pincushion distortion $1 + k_1 r^2 + k_2 r^4 + k_3 r^6$ monotonically increasing\n",
    "\n",
    "i.e  $k_1=+1.5$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/Pincushion_distortion.svg\" height=\"250\" width=\"250\" />\n",
    "\n",
    "\n",
    "## 1.2 Barrel Distortion (Negative Radial Distortions)\n",
    "\n",
    "In barrel distortion $1 + k_1 r^2 + k_2 r^4 + k_3 r^6$ monotonically decreasing\n",
    "\n",
    "i.e  <img  src=\"https://latex.codecogs.com/svg.latex?k_1%3D-1.5\" alt=\"https://latex.codecogs.com/svg.latex?k_1=-1.5\" />\n",
    "\n",
    "<img src=\"images/Barrel_distortion.svg\" height=\"250\" width=\"250\" />\n",
    "\n",
    "\n",
    "## 1.3 Mustache Distortion\n",
    "<img src=\"images/Mustache_distortion.svg\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1.4 Tangential Distortions\n",
    "Decentering distortion is a result of the lens assembly not being centered over and parallel to the image plane as the main reason.\n",
    "\n",
    "\n",
    "|   |   |\n",
    "|---|---|\n",
    "|<img src=\"images/tangential_distortions.svg\" height=\"250\" width=\"250\"/>   | <img src=\"images/radial-and-tangential-distortion.png\" height=\"270\" width=\"350\"/>   |\n",
    "|[image courtesy](https://www.tangramvision.com/blog/camera-modeling-exploring-distortion-and-distortion-models-part-i)   |      [image courtesy](https://www.researchgate.net/publication/260728375_Laboratory_calibration_of_star_sensor_with_installation_error_using_a_nonlinear_distortion_model)  |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. OpenCV Lens Distortion Model\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?\\begin{bmatrix}x\\\\y\\\\z%20\\end{bmatrix}=%20R\\begin{bmatrix}%20X\\\\%20%20Y\\\\%20%20Z%20\\end{bmatrix}+t\" alt=\"https://latex.codecogs.com/svg.latex?\\begin{bmatrix}x\\\\y\\\\z \\end{bmatrix}= R\\begin{bmatrix} X\\\\  Y\\\\  Z \\end{bmatrix}+t\" />\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20%7Bx%7D%27%3D%5Cfrac%7Bx%7D%7Bz%7D%20%5C%5C%20%7By%7D%27%3D%5Cfrac%7By%7D%7Bz%7D%20%5Cend%7Bmatrix%7D%5Cright.\" alt=\"https://latex.codecogs.com/svg.latex?\\left\\{\\begin{matrix}\n",
    "{x}'=\\frac{x}{z} \n",
    "\\\\ \n",
    "{y}'=\\frac{y}{z} \n",
    "\\end{matrix}\\right.\" />\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20%7Bx%7D%27%27%3D%7Bx%7D%27%20%5Cfrac%7B1&plus;k_1r%5E2&plus;%20k_2r%5E4&plus;%20k_3r%5E6%7D%7B1&plus;k_4r%5E2%20&plus;k_5r%5E4%20&plus;%20k_6r6%20%7D%20&plus;2p_1%7Bx%7D%27%7By%7D%27&plus;p_2%28r%5E2&plus;2%7Bx%7D%27%5E2%29%20&plus;s_1r%5E2&plus;s_2r%5E4%20%5C%5C%20%5C%5C%20%7By%7D%27%27%3D%7By%7D%27%20%5Cfrac%7B1&plus;k_1r%5E2&plus;%20k_2r%5E4&plus;%20k_3r%5E6%7D%7B1&plus;k_4r%5E2%20&plus;k_5r%5E4%20&plus;%20k_6r6%20%7D&plus;p_1%28r%5E2&plus;2%7Bx%7D%27%5E2%29%20&plus;2p_2%7Bx%7D%27%7By%7D%27%20&plus;s_3r%5E2&plus;s_4r%5E4%20%5Cend%7Bmatrix%7D%5Cright.\" \n",
    "alt=\"https://latex.codecogs.com/svg.latex?\\left\\{\\begin{matrix} {x}''={x}' \\frac{1+k_1r^2+ k_2r^4+ k_3r^6}{1+k_4r^2 +k_5r^4 + k_6r6 } +2p_1{x}'{y}'+p_2(r^2+2{x}'^2) +s_1r^2+s_2r^4 \\\\ \\\\ {y}''={y}' \\frac{1+k_1r^2+ k_2r^4+ k_3r^6}{1+k_4r^2 +k_5r^4 + k_6r6 }+p_1(r^2+2{x}'^2) +2p_2{x}'{y}' +s_3r^2+s_4r^4 \\end{matrix}\\right.\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20u%3Df_x%20%5Ctimes%20%7Bx%7D%27%27&plus;c_x%20%5C%5C%20v%3Df_y%20%5Ctimes%20%7By%7D%27%27&plus;c_y%20%5Cend%7Bmatrix%7D%5Cright.\" alt=\"https://latex.codecogs.com/svg.latex?\\left\\{\\begin{matrix} u=f_x \\times {x}''+c_x \\\\ v=f_y \\times {y}''+c_y \n",
    "\\end{matrix}\\right.\" />\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Ctext%7Bwhere%3A%20%7D%20r%5E2%3D%7Bx%7D%27%5E2%20&plus;%20%7By%7D%27%5E2\" alt=\"https://latex.codecogs.com/svg.latex?\\text{where: } r^2={x}'^2 + {y}'^2\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The distortion parameters:\n",
    "1. Radial coefficients <img src=\"https://latex.codecogs.com/svg.latex?k_1%2C%20k_2%2C%20k_3%2C%20k_4%2C%20k_5%2C%20%5Ctext%7B%20and%20%7D%20k_6\" alt=\"https://latex.codecogs.com/svg.latex?k_1, k_2, k_3, k_4, k_5, \\text{ and }  k_6\" />.\n",
    "2. Tangential distortion coefficients <img src=\"https://latex.codecogs.com/svg.latex?p_1%20%5Ctext%7B%20and%20%7D%20p_2\" alt=\"https://latex.codecogs.com/svg.latex?p_1 \\text{ and }  p_2\" />. \n",
    "3. Thin prism distortion coefficients <img src=\"https://latex.codecogs.com/svg.latex?s_1%2C%20s_2%2C%20s_3%2C%20%5Ctext%7B%20and%20%7D%20s_4\" alt=\"https://latex.codecogs.com/svg.latex?s_1, s_2, s_3, \\text{ and }  s_4\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In the presence of tangential distortion, model is extended as:\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20u%20%3Df_x%20x%27%27%20&plus;%20c_x%20%5C%5C%20v%3Df_y%20y%27%27%20&plus;%20c_y%20%5Cend%7Bmatrix%7D%5Cright.\" alt=\"\\left\\{\\begin{matrix}\n",
    "u =f_x x'' + c_x \\\\ \n",
    "v=f_y y'' + c_y \n",
    "\\end{matrix}\\right.\" />\n",
    "\n",
    "\n",
    "where\n",
    "\n",
    "\n",
    "\n",
    "Radial distortion is always monotonic for real lenses, and if the estimator produces a non-monotonic result, this should be considered a calibration failure.A failed estimation result may look deceptively good near the image center but will work poorly in e.g. AR/SFM applications. The optimization method used in OpenCV camera calibration does not include these constraints as the framework does not support the required integer programming and polynomial inequalities. See issue [#15992](https://github.com/opencv/opencv/issues/15992) for additional information.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Image Resolution and Distortion Coefficient\n",
    "The distortion coefficients <img src=\"https://latex.codecogs.com/svg.image?k_1,k_2,p_1,p_2,k_3,k_4,k_5,k_6\" title=\"https://latex.codecogs.com/svg.image?k_1,k_2,p_1,p_2,k_3,k_4,k_5,k_6\" /> \n",
    "do not depend on the scene viewed and they remain the **same** regardless of image resolution. If, for example, a camera has been calibrated on images of 320 x 240 resolution, absolutely the same distortion coefficients can be used for 640 x 480 images from the same camera\n",
    "\n",
    "However, <img src=\"https://latex.codecogs.com/svg.image?f_x\" title=\"https://latex.codecogs.com/svg.image?f_x\" />, <img src=\"https://latex.codecogs.com/svg.image?f_y\" title=\"https://latex.codecogs.com/svg.image?f_y\" />, <img src=\"https://latex.codecogs.com/svg.image?c_x\" title=\"https://latex.codecogs.com/svg.image?c_x\" />, and <img src=\"https://latex.codecogs.com/svg.image?c_y\" title=\"https://latex.codecogs.com/svg.image?c_y\" /> need to be scaled appropriately.\n",
    "\n",
    "```\n",
    "fx.new=(new width resolution/old width resolution)*fx.old\n",
    "fy.new=(new height resolution/old height resolution)*fy.old\n",
    "\n",
    "cx.new=(new width resolution/old width resolution)*cx.old\n",
    "cy.new=(new height resolution/old height resolution)*cy.old\n",
    "```\n",
    "Refs: [1](https://stackoverflow.com/questions/44888119/c-opencv-calibration-of-the-camera-with-different-resolution),\n",
    "\n",
    "\n",
    "\n",
    "# 4. Distortion Models\n",
    "\n",
    "## 4.1  Brown-Conrady\n",
    "\n",
    "The Brown-Conrady model corrects both for radial distortion and for tangential distortion as a series of higher order polynomial. In the following all points are n the image plane with Cartesian coordinate and not pixel based coordinate.\n",
    "\n",
    "### 4.1.1 Radial Distortion\n",
    "<img src=\"images/radial_distortion_image_plane.svg\" height=\"250\" width=\"250\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\delta&space;r=&space;k_1&space;r^3&space;&plus;&space;k_2&space;r^5&space;&plus;&space;k_3&space;r^7&space;&plus;&space;...&space;&plus;&space;k_n&space;r^{n&plus;2}\" title=\"https://latex.codecogs.com/svg.image?\\delta r= k_1 r^3 + k_2 r^5 + k_3 r^7 + ... + k_n r^{n+2}\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\delta&space;x_r&space;=&space;\\sin(\\psi)&space;\\delta&space;r&space;=&space;\\frac{x}{r}&space;(k_1r^3&space;&plus;&space;k_2r^5&space;&plus;&space;k_3r^7)\" title=\"https://latex.codecogs.com/svg.image?\\delta x_r = \\sin(\\psi) \\delta r = \\frac{x}{r} (k_1r^3 + k_2r^5 + k_3r^7)\" />\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\delta&space;y_r&space;=&space;\\cos(\\psi)&space;\\delta&space;r&space;=&space;\\frac{y}{r}&space;(k_1r^3&space;&plus;&space;k_2r^5&space;&plus;&space;k_3r^7)\" title=\"https://latex.codecogs.com/svg.image?\\delta y_r = \\cos(\\psi) \\delta r = \\frac{y}{r} (k_1r^3 + k_2r^5 + k_3r^7)\" />\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?(x_{\\mathrm&space;{d}&space;},\\&space;y_{\\mathrm&space;{d}&space;})\" title=\"https://latex.codecogs.com/svg.image?(x_{\\mathrm {d} },\\ y_{\\mathrm {d} })\" /> is the distorted image point\n",
    "\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?(x_{\\mathrm&space;{u}&space;},\\&space;y_{\\mathrm&space;{u}&space;})\" title=\"https://latex.codecogs.com/svg.image?(x_{\\mathrm {u} },\\ y_{\\mathrm {u} })\" /> is the undistorted image point\n",
    "\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?(x_{\\mathrm&space;{c}&space;},\\&space;y_{\\mathrm&space;{c}&space;})\" title=\"https://latex.codecogs.com/svg.image?(x_{\\mathrm {c} },\\ y_{\\mathrm {c} })\" /> is the distortion center\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?r={\\displaystyle&space;{\\sqrt&space;{(x_{\\mathrm&space;{d}&space;}-x_{\\mathrm&space;{c}&space;})^{2}&plus;(y_{\\mathrm&space;{d}&space;}-y_{\\mathrm&space;{c}&space;})^{2}}}}\" title=\"https://latex.codecogs.com/svg.image?r={\\displaystyle {\\sqrt {(x_{\\mathrm {d} }-x_{\\mathrm {c} })^{2}+(y_{\\mathrm {d} }-y_{\\mathrm {c} })^{2}}}}\" />\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### 4.1.2 Tangential distortion:\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\delta&space;x_t&space;=&space;p_1(r^2&space;&plus;&space;2x^2)&space;&plus;&space;2p_2xy\" title=\"https://latex.codecogs.com/svg.image?\\delta x_t = p_1(r^2 + 2x^2) + 2p_2xy\" />\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\delta&space;y_t&space;=&space;p_2(r^2&space;&plus;&space;2y^2)&space;&plus;&space;2p_1xy\" title=\"https://latex.codecogs.com/svg.image?\\delta y_t = p_2(r^2 + 2y^2) + 2p_1xy\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### 4.1.3  Both Distortion Together\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?{\\displaystyle&space;{\\begin{alignedat}{}x_{\\mathrm&space;{u}&space;}=x_{\\mathrm&space;{d}&space;}&&plus;(x_{\\mathrm&space;{d}&space;}-x_{\\mathrm&space;{c}&space;})(K_{1}r^{2}&plus;K_{2}r^{4}&plus;\\cdots&space;)&plus;(P_{1}(r^{2}&plus;2(x_{\\mathrm&space;{d}&space;}-x_{\\mathrm&space;{c}&space;})^{2})\\\\&&plus;2P_{2}(x_{\\mathrm&space;{d}&space;}-x_{\\mathrm&space;{c}&space;})(y_{\\mathrm&space;{d}&space;}-y_{\\mathrm&space;{c}&space;}))(1&plus;P_{3}r^{2}&plus;P_{4}r^{4}\\cdots&space;)\\\\y_{\\mathrm&space;{u}&space;}=y_{\\mathrm&space;{d}&space;}&&plus;(y_{\\mathrm&space;{d}&space;}-y_{\\mathrm&space;{c}&space;})(K_{1}r^{2}&plus;K_{2}r^{4}&plus;\\cdots&space;)&plus;(2P_{1}(x_{\\mathrm&space;{d}&space;}-x_{\\mathrm&space;{c}&space;})(y_{\\mathrm&space;{d}&space;}-y_{\\mathrm&space;{c}&space;})\\\\&&plus;P_{2}(r^{2}&plus;2(y_{\\mathrm&space;{d}&space;}-y_{\\mathrm&space;{c}&space;})^{2}))(1&plus;P_{3}r^{2}&plus;P_{4}r^{4}\\cdots&space;),\\end{alignedat}}}\" title=\"https://latex.codecogs.com/svg.image?{\\displaystyle {\\begin{alignedat}{}x_{\\mathrm {u} }=x_{\\mathrm {d} }&+(x_{\\mathrm {d} }-x_{\\mathrm {c} })(K_{1}r^{2}+K_{2}r^{4}+\\cdots )+(P_{1}(r^{2}+2(x_{\\mathrm {d} }-x_{\\mathrm {c} })^{2})\\\\&+2P_{2}(x_{\\mathrm {d} }-x_{\\mathrm {c} })(y_{\\mathrm {d} }-y_{\\mathrm {c} }))(1+P_{3}r^{2}+P_{4}r^{4}\\cdots )\\\\y_{\\mathrm {u} }=y_{\\mathrm {d} }&+(y_{\\mathrm {d} }-y_{\\mathrm {c} })(K_{1}r^{2}+K_{2}r^{4}+\\cdots )+(2P_{1}(x_{\\mathrm {d} }-x_{\\mathrm {c} })(y_{\\mathrm {d} }-y_{\\mathrm {c} })\\\\&+P_{2}(r^{2}+2(y_{\\mathrm {d} }-y_{\\mathrm {c} })^{2}))(1+P_{3}r^{2}+P_{4}r^{4}\\cdots ),\\end{alignedat}}}\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?K_{n}&space;\" title=\"https://latex.codecogs.com/svg.image?K_{n} \" /> is the <img src=\"https://latex.codecogs.com/svg.image?n^{\\mathrm&space;{th}&space;}\" title=\"https://latex.codecogs.com/svg.image?n^{\\mathrm {th} }\" /> radial distortion coefficient.\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?P_{n}\" title=\"https://latex.codecogs.com/svg.image?P_{n}\" /> is the <img src=\"https://latex.codecogs.com/svg.image?n^{\\mathrm&space;{th}&space;}\" title=\"https://latex.codecogs.com/svg.image?n^{\\mathrm {th} }\" /> tangential distortion coefficient.\n",
    "\n",
    "In practice, only the <img src=\"https://latex.codecogs.com/svg.image?k_1\" title=\"https://latex.codecogs.com/svg.image?k_1\" />, <img src=\"https://latex.codecogs.com/svg.image?k_2\" title=\"https://latex.codecogs.com/svg.image?k_1\" /> and <img src=\"https://latex.codecogs.com/svg.image?k_3\" title=\"https://latex.codecogs.com/svg.image?k_3\" /> and <img src=\"https://latex.codecogs.com/svg.image?p_1\" title=\"https://latex.codecogs.com/svg.image?p_1\" />, <img src=\"https://latex.codecogs.com/svg.image?p_2\" title=\"https://latex.codecogs.com/svg.image?p_2\" /> \n",
    "terms are typically used\n",
    "\n",
    "\n",
    "\n",
    "- Barrel distortion typically will have a negative term for <img src=\"https://latex.codecogs.com/svg.image?K_{1}&space;\" title=\"https://latex.codecogs.com/svg.image?K_{1} \" /> \n",
    "- Pincushion distortion will have a positive value for <img src=\"https://latex.codecogs.com/svg.image?K_{1}&space;\" title=\"https://latex.codecogs.com/svg.image?K_{1} \" /> . \n",
    "- Moustache distortion will have a non-monotonic radial geometric series where for some <img src=\"https://latex.codecogs.com/svg.image?r\" title=\"https://latex.codecogs.com/svg.image?r\" /> the sequence will change sign.\n",
    "\n",
    "\n",
    "\n",
    "## 4.2  Division Model\n",
    "\n",
    "\n",
    "provides a more accurate approximation than Brown-Conrady's even-order polynomial model. For radial distortion, this division model is often preferred over the Brown–Conrady model, as it requires fewer terms to more accurately describe severe distortion\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?{\\begin{aligned}x_{\\mathrm&space;{u}&space;}&=x_{\\mathrm&space;{c}&space;}&plus;{\\frac&space;{x_{\\mathrm&space;{d}&space;}-x_{\\mathrm&space;{c}&space;}}{1&plus;K_{1}r^{2}&plus;K_{2}r^{4}&plus;\\cdots&space;}}\\\\y_{\\mathrm&space;{u}&space;}&=y_{\\mathrm&space;{c}&space;}&plus;{\\frac&space;{y_{\\mathrm&space;{d}&space;}-y_{\\mathrm&space;{c}&space;}}{1&plus;K_{1}r^{2}&plus;K_{2}r^{4}&plus;\\cdots&space;}},\\end{aligned}}\" title=\"https://latex.codecogs.com/svg.image?{\\begin{aligned}x_{\\mathrm {u} }&=x_{\\mathrm {c} }+{\\frac {x_{\\mathrm {d} }-x_{\\mathrm {c} }}{1+K_{1}r^{2}+K_{2}r^{4}+\\cdots }}\\\\y_{\\mathrm {u} }&=y_{\\mathrm {c} }+{\\frac {y_{\\mathrm {d} }-y_{\\mathrm {c} }}{1+K_{1}r^{2}+K_{2}r^{4}+\\cdots }},\\end{aligned}}\" />\n",
    "\n",
    "\n",
    "Refs: [1](https://www.tangramvision.com/blog/camera-modeling-exploring-distortion-and-distortion-models-part-i),\n",
    "[2](https://www.robots.ox.ac.uk/~vgg/publications/2001/Fitzgibbon01b/fitzgibbon01b.pdf), [3](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr98-71.pdf), [4](https://ori.codes/artificial-intelligence/camera-calibration/camera-distortions/), [5](https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb83652-6328-41cc-8366-f84173a7026b",
   "metadata": {},
   "source": [
    "- [Undistorting Points](#undistorting-points)\n",
    "  * [initUndistortRectifyMap](#initundistortrectifymap)\n",
    "  * [undistort](#undistort)\n",
    "\n",
    "\n",
    "## Undistorting Points\n",
    "\n",
    "### initUndistortRectifyMap\n",
    "The following function computes the `undistortion` and `rectification transformation`. The undistorted is image that has been captured with a camera using the `camera matrix =newCameraMatrix` and zero distortion.\n",
    "\n",
    "1. In the case of a monocular camera, `newCameraMatrix` is usually equal to `cameraMatrix` or it can be computed by getOptimalNewCameraMatrix for better control over scaling.\n",
    "\n",
    "2. In case of a stereo camera, `newCameraMatrix` is normally set to `P1` or `P2` computed by `stereoRectify` .\n",
    "\n",
    "\n",
    "\n",
    "```cpp\n",
    "void cv::initUndistortRectifyMap\t(\tInputArray \tcameraMatrix,\n",
    "InputArray \tdistCoeffs,\n",
    "InputArray \tR,\n",
    "InputArray \tnewCameraMatrix,\n",
    "Size \tsize,\n",
    "int \tm1type,\n",
    "OutputArray \tmap1,\n",
    "OutputArray \tmap2 \n",
    ")\t\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "1. `cameraMatrix`:\n",
    "<br/>\n",
    "$A=\\begin{bmatrix}\n",
    "f_x & 0 & c_x\\\\ \n",
    "0 & f_y & c_y\\\\ \n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "2. `distCoeffs`: input vector of distortion coefficients 4, 5, 8, 12 or 14 elements:\n",
    "$k1,k2,p1,p2[,k3[,k4,k5,k6[,s1,s2,s3,s4[,τx,τy]]]] $\n",
    "\n",
    "\n",
    "3. `R`: Optional rectification transformation in the object space (3x3 matrix). `R1 `or `R2` , computed by `stereoRectify` can be passed here. If the matrix is empty, the identity transformation is assumed. In `initUndistortRectifyMap` R is assumed to be an identity matrix.\n",
    "\n",
    "\n",
    "4. `newCameraMatrix`: New camera matrix\n",
    "\n",
    "\n",
    "$A=\\begin{bmatrix}\n",
    "f'_x & 0 & c'_x\\\\ \n",
    "0 & f'_y & c'_y\\\\ \n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "For each observed point coordinate (u,v) the function computes:\n",
    "\n",
    "$\\begin{array}{l} x \\leftarrow (u - {c'}_x)/{f'}_x \\\\ y \\leftarrow (v - {c'}_y)/{f'}_y \\\\ {[X\\,Y\\,W]} ^T \\leftarrow R^{-1}*[x \\, y \\, 1]^T \\\\ x' \\leftarrow X/W \\\\ y' \\leftarrow Y/W \\\\ r^2 \\leftarrow x'^2 + y'^2 \\\\ x'' \\leftarrow x' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6} + 2p_1 x' y' + p_2(r^2 + 2 x'^2) + s_1 r^2 + s_2 r^4\\\\ y'' \\leftarrow y' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6} + p_1 (r^2 + 2 y'^2) + 2 p_2 x' y' + s_3 r^2 + s_4 r^4  \\end{array}$\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "$s\\begin{bmatrix}\n",
    "{x}'''\\\\ \n",
    "{}y'''\\\\ \n",
    "1\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "R_{33}(\\tau_x, \\tau_y) & 0 &{-R_{13}((\\tau_x, \\tau_y)}  \\\\ \n",
    "0 & R_{33}(\\tau_x, \\tau_y)  & -R_{23}(\\tau_x, \\tau_y)\\\\ \n",
    "0 & 0 & 1 \n",
    "\\end{bmatrix}R(\\tau_x, \\tau_y)\\begin{bmatrix}\n",
    "{x}''\\\\ \n",
    "{y}''\\\\ \n",
    "1\n",
    "\\end{bmatrix}$\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "$\\\\map_x(u,v) \\leftarrow x''' f_x + c_x \\\\ map_y(u,v) \\leftarrow y''' f_y + c_y$\n",
    "\n",
    "\n",
    "where $k1,k2,p1,p2[,k3[,k4,k5,k6[,s1,s2,s3,s4[,τx,τy]]]] $ are the distortion coefficients.\n",
    "\n",
    "\n",
    "\n",
    "In the case of a stereo camera, this function is called twice: once for each camera head, after `stereoRectify`, which in its turn is called after `stereoCalibrate`. But if the stereo camera was not calibrated, it is still possible to compute the rectification transformations directly from the fundamental matrix using `stereoRectifyUncalibrated`. For each camera, the function computes `homography H` as the rectification transformation in a pixel domain, not a rotation matrix` R` in 3D space. `R` can be computed from H as\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Ctext%7BR%7D%20%3D%20%5Ctext%7BcameraMatrix%7D%20%5E%7B-1%7D%20%5Ccdot%20%5Ctext%7BH%7D%20%5Ccdot%20%5Ctext%7BcameraMatrix%7D\" alt=\"https://latex.codecogs.com/svg.latex?\\text{R} = \\text{cameraMatrix} ^{-1} \\cdot \\text{H} \\cdot \\text{cameraMatrix}\" />\n",
    "\n",
    "\n",
    "\n",
    "Refs: [1](https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a), [2](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#initundistortrectifymap)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### cv::undistortPoints\n",
    "This function is similar to `initUndistortRectifyMap` but it operates on a sparse set of points\n",
    "```cpp\n",
    "void cv::undistortPoints\t(\tInputArray \tsrc,\n",
    "OutputArray \tdst,\n",
    "InputArray \tcameraMatrix,\n",
    "InputArray \tdistCoeffs,\n",
    "InputArray \tR = noArray(),\n",
    "InputArray \tP = noArray() \n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In OpenCV `cv::undistort`does the followings:\n",
    "For each pixel of the destination lens-corrected image do:\n",
    "\n",
    "- Convert the pixel coordinates `(u_dst, v_dst)` to normalized coordinates `(x_d, y_d`) using the inverse of the calibration matrix `K`,\n",
    "- Apply the lens-distortion model, as displayed above, to obtain the distorted normalized coordinates `(x_u, y_u)`,\n",
    "- Convert `(x_u, y_u)` to distorted pixel coordinates using the calibration matrix `K`,\n",
    "- Use the interpolation method of your choice to find the intensity/depth associated with the pixel coordinates `(u_src, v_src)` in the source image, and assign this intensity/depth to the current destination pixel.\n",
    "\n",
    "\n",
    "Refs: [1](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#camera-calibration-and-3d-reconstruction), [2](https://stackoverflow.com/questions/21958521/understanding-of-opencv-undistortion), [3](https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga69f2545a8b62a6b0fc2ee060dc30559d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  cv::UndistortTypes in OpenCV:\n",
    "\n",
    "**`cv::UndistortTypes`** is an enumeration (enum) in OpenCV's C++ API that specifies different distortion correction models used in the `undistort` function. This function is essential for rectifying images captured with lenses that introduce geometric distortions, such as barrel or pincushion distortion.\n",
    "\n",
    "**Available options in `cv::UndistortTypes`:**\n",
    "\n",
    "- **`cv::PROJ_SPHERICAL_ORTHO` (value: 0):** This model assumes a spherical projection with orthographic rectification. It's suitable for images captured with fisheye lenses that have a very wide field of view. In this model, straight lines in the real world may appear curved in the distorted image, but after undistortion using `cv::PROJ_SPHERICAL_ORTHO`, they will be represented as straight lines.\n",
    "\n",
    "- **`cv::PROJ_SPHERICAL_EQRECT` (value: 1):** This model also assumes a spherical projection, but with equirectangular rectification. It's appropriate for panoramic images where the goal is to create a rectangular image with minimal distortion. Straight lines in the real world may be slightly bent after undistortion, but the overall distortion is reduced.\n",
    "\n",
    "**Choosing the appropriate model:**\n",
    "\n",
    "The choice between these models depends on the type of lens distortion present in your image and the desired outcome.\n",
    "\n",
    "- If you have a fisheye image and want to preserve straight lines, use `cv::PROJ_SPHERICAL_ORTHO`.\n",
    "- If you have a panoramic image and want a rectangular representation with minimal distortion, use `cv::PROJ_SPHERICAL_EQRECT`.\n",
    "\n",
    "**Additional considerations:**\n",
    "\n",
    "- To use these models effectively, you'll need the camera calibration parameters (camera matrix and distortion coefficients) obtained through a calibration process. These parameters are typically used as input to the `undistort` function.\n",
    "- OpenCV provides other distortion correction models beyond these two, which might be more suitable for specific lens types or applications. Refer to the OpenCV documentation for a comprehensive list.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## fisheye::undistortPoints\n",
    "\n",
    "Refs: [1](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#fisheye-undistortpoints)\n",
    "\n",
    "\n",
    "\n",
    "## fisheye::initUndistortRectifyMap\n",
    "\n",
    "Refs: [1](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#fisheye-initundistortrectifymap)\n",
    "\n",
    "\n",
    "## fisheye::undistortImage\n",
    "\n",
    "Refs: [1](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#fisheye-undistortimage)\n",
    "\n",
    "\n",
    "## cv::undistort\n",
    "\n",
    "The function transforms an image to compensate radial and tangential lens distortion.\n",
    "\n",
    "The function is simply a combination of `initUndistortRectifyMap` (with unity `R` ) and `remap` (with bilinear interpolation). \n",
    "\n",
    "\n",
    "```cpp\n",
    "void cv::undistort\t(\tInputArray \tsrc,\n",
    "OutputArray \tdst,\n",
    "InputArray \tcameraMatrix,\n",
    "InputArray \tdistCoeffs,\n",
    "InputArray \tnewCameraMatrix = noArray() \n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "Refs: [1](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga69f2545a8b62a6b0fc2ee060dc30559d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## cv::undistortImagePoints\n",
    "\n",
    "```cpp\n",
    "\n",
    "void cv::undistortImagePoints\t(\tInputArray \tsrc,\n",
    "OutputArray \tdst,\n",
    "InputArray \tcameraMatrix,\n",
    "InputArray \tdistCoeffs,\n",
    "TermCriteria \t= TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS, 5, 0.01) \n",
    ")\n",
    "```\n",
    "- `src`: Observed points position, 2xN/Nx2 1-channel or 1xN/Nx1 2-channel (CV_32FC2 or CV_64FC2) (or vector<Point2f> ).\n",
    "\n",
    "Compute undistorted image points position\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9efc10b-6ae6-4e48-8086-c62df13ab453",
   "metadata": {},
   "source": [
    "Below is a high-level summary of how OpenCV’s standard pinhole camera model with distortion works and how points can be undistorted (i.e., how to remove the distortion). We will walk through:\n",
    "\n",
    "1. The pinhole camera projection model (ideal, without distortion).  \n",
    "2. The distortion model as used by OpenCV (commonly the Brown–Conrady model).  \n",
    "3. How the distorted points are mapped to the image.  \n",
    "4. How undistortion is performed in practice.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Ideal Pinhole Camera Model (Without Distortion)\n",
    "\n",
    "OpenCV typically uses the pinhole camera model as its baseline. If we have a 3D point $(X, Y, Z)$ in the camera coordinate system (with $Z > 0$), the ideal normalized projection $(x', y')$ onto the camera’s image plane (the normalized coordinates) is:\n",
    "\n",
    "$\n",
    "x' = \\frac{X}{Z}, \n",
    "\\quad\n",
    "y' = \\frac{Y}{Z}.\n",
    "$\n",
    "\n",
    "Then, to map from these normalized coordinates to pixel coordinates $(u, v)$, we use the camera intrinsic matrix. The most common (simplified) version is:\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "u &= f_x \\, x' + c_x, \\\\\n",
    "v &= f_y \\, y' + c_y,\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "- $f_x, f_y$ are the focal lengths in the $x$ and $y$ directions (in pixels).  \n",
    "- $(c_x, c_y)$ is the principal point (in pixels).  \n",
    "\n",
    "Without lens distortion, $(u, v)$ is just a linear transform of $(x', y')$. However, real camera lenses introduce distortions that must be modeled.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Distortion Model in OpenCV\n",
    "\n",
    "OpenCV typically implements a radial-tangential (Brown–Conrady) distortion model (and can optionally extend it). The most common parameters are:\n",
    "\n",
    "- **Radial distortion coefficients:** $k_1, k_2, k_3$  \n",
    "- **Tangential distortion coefficients:** $p_1, p_2$\n",
    "\n",
    "### Radial Distortion\n",
    "\n",
    "Radial distortion depends on the distance $r$ from the optical axis in the normalized image plane:\n",
    "\n",
    "$\n",
    "r^2 = {x'}^2 + {y'}^2.\n",
    "$\n",
    "\n",
    "Radial distortion modifies the normalized coordinates $(x',y')$ roughly by a scale factor that depends on $r$:\n",
    "\n",
    "$\n",
    "\\text{scale} \\;=\\; 1 \\;+\\; k_1\\,r^2 \\;+\\; k_2\\,r^4 \\;+\\; k_3\\,r^6.\n",
    "$\n",
    "\n",
    "Hence, the radially distorted coordinates would be:\n",
    "\n",
    "$\n",
    "x_{\\mathrm{rad}} = x' \\cdot \\text{scale}, \n",
    "\\quad\n",
    "y_{\\mathrm{rad}} = y' \\cdot \\text{scale}.\n",
    "$\n",
    "\n",
    "### Tangential Distortion\n",
    "\n",
    "Tangential distortion arises when the lens and the image plane are not perfectly parallel. The tangential distortion adds another shift to $(x',y')$ that depends on $p_1, p_2$. In normalized coordinates, the tangential distortion is:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "x_{\\mathrm{tan}} &= 2 \\, p_1 \\, x' \\, y' + p_2 \\bigl(r^2 + 2 {x'}^2 \\bigr), \\\\\n",
    "y_{\\mathrm{tan}} &= p_1 \\bigl(r^2 + 2 {y'}^2 \\bigr) + 2 \\, p_2 \\, x' \\, y'.\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "### Combined Distortion Model\n",
    "\n",
    "Putting radial and tangential distortion together, if $(x',y')$ are the ideal normalized coordinates, the final distorted normalized coordinates $(x'', y'')$ in OpenCV are often written as:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "x'' &= x' \\cdot (1 + k_1 \\, r^2 + k_2 \\, r^4 + k_3 \\, r^6) \n",
    "       \\;+\\; 2 \\, p_1 \\, x' \\, y' \n",
    "       \\;+\\; p_2 \\,(r^2 + 2\\,{x'}^2), \\\\\n",
    "y'' &= y' \\cdot (1 + k_1 \\, r^2 + k_2 \\, r^4 + k_3 \\, r^6) \n",
    "       \\;+\\; p_1 \\,(r^2 + 2\\,{y'}^2)\n",
    "       \\;+\\; 2 \\, p_2 \\, x' \\, y'.\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Here again, $r^2 = x'^2 + y'^2$.  \n",
    "\n",
    "Finally, the pixel coordinates $(u,v)$ of the distorted point are:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "u &= f_x \\, x'' + c_x, \\\\\n",
    "v &= f_y \\, y'' + c_y.\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Projection With Distortion Coefficients (Summary)\n",
    "\n",
    "Putting it all together for a 3D point $(X,Y,Z)$:\n",
    "\n",
    "1. Convert $(X,Y,Z)$ to normalized coordinates $(x',y')$:\n",
    "   $\n",
    "   x' = \\frac{X}{Z}, \n",
    "   \\quad\n",
    "   y' = \\frac{Y}{Z}.\n",
    "   $\n",
    "\n",
    "2. Compute the distortion factors (radial and tangential) for $(x',y')$.  \n",
    "3. Apply distorted scaling to get $(x'',y'')$.  \n",
    "4. Convert $(x'', y'')$ to pixel coordinates $(u,v)$ using the intrinsic matrix.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d375ea5-0594-4868-b7ab-1437c91248da",
   "metadata": {},
   "source": [
    "## 4. Undistortion\n",
    "\n",
    "**Undistortion** is the process of finding the ideal (undistorted) image coordinates $(x', y')$ given the distorted pixel coordinates $(u, v)$. Put another way, we want to invert the above distortion equations:\n",
    "\n",
    "1. Convert the distorted pixel coordinates $(u, v)$ to distorted normalized coordinates $(x'', y'')$:\n",
    " \n",
    "   $\n",
    "   x'' = \\frac{u - c_x}{f_x}, \n",
    "   \\quad\n",
    "   y'' = \\frac{v - c_y}{f_y}.\n",
    "   $\n",
    "\n",
    "2. We need to solve for $(x',y')$ (the ideal normalized coordinates) from:\n",
    "\n",
    "   $\n",
    "   \\begin{aligned}\n",
    "   x'' &= x' \\cdot (1 + k_1 \\, r^2 + k_2 \\, r^4 + k_3 \\, r^6) \n",
    "          \\;+\\; 2 \\, p_1 \\, x' \\, y' \n",
    "          \\;+\\; p_2 \\,(r^2 + 2\\,{x'}^2), \\\\\n",
    "   y'' &= y' \\cdot (1 + k_1 \\, r^2 + k_2 \\, r^4 + k_3 \\, r^6) \n",
    "          \\;+\\; p_1 \\,(r^2 + 2\\,{y'}^2)\n",
    "          \\;+\\; 2 \\, p_2 \\, x' \\, y',\n",
    "   \\end{aligned}\n",
    "   $\n",
    "   \n",
    "   where\n",
    "\n",
    "   $r^2 = x'^2 + y'^2$.\n",
    "\n",
    "Because these equations are nonlinear, there is generally no simple closed-form for $(x',y')$ in terms of $(x'',y'')$. In practice, OpenCV (and most other libraries) uses an **iterative** approach or a polynomial approximation to invert these equations.\n",
    "\n",
    "### Iterative Approach (Conceptual)\n",
    "\n",
    "A common iterative approach (Gauss–Newton style or simple fixed-point iteration) starts with an initial guess $(\\hat{x}', \\hat{y}') = (x'', y'')$ and then refines the guess. On each iteration:\n",
    "\n",
    "1. You compute the forward distortion of $(\\hat{x}', \\hat{y}')$.  \n",
    "2. Compare it to $(x'', y'')$.  \n",
    "3. Update $(\\hat{x}', \\hat{y}')$ by a small correction so that the difference (residual) shrinks.  \n",
    "\n",
    "After a few iterations, $(\\hat{x}', \\hat{y}')$ converges to the solution that satisfies the distortion equations.  \n",
    "\n",
    "Finally, once you have $(x', y')$, the undistorted pixel coordinates can be found (if desired) by applying the intrinsic matrix **without** the distortion terms:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "u_{\\text{undistorted}} &= f_x \\, x' + c_x, \\\\\n",
    "v_{\\text{undistorted}} &= f_y \\, y' + c_y.\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98eec7-6ac4-489c-92ea-9c825e39230e",
   "metadata": {},
   "source": [
    "## 5. Summary of the Key Equations\n",
    "\n",
    "1. **Forward Distortion** (from undistorted normalized $(x', y')$ to distorted normalized $(x'',y'')$):\n",
    "\n",
    "   $\n",
    "   \\begin{aligned}\n",
    "   r^2 &= x'^2 + y'^2, \\\\\n",
    "   \\text{scale} &= 1 + k_1\\,r^2 + k_2\\,r^4 + k_3\\,r^6, \\\\\n",
    "   x'' &= x' \\cdot \\text{scale} \\;+\\; 2\\,p_1\\,x'\\,y' \\;+\\; p_2\\,(r^2 + 2\\,x'^2), \\\\\n",
    "   y'' &= y' \\cdot \\text{scale} \\;+\\; p_1\\,(r^2 + 2\\,y'^2) \\;+\\; 2\\,p_2\\,x'\\,y'.\n",
    "   \\end{aligned}\n",
    "   $\n",
    "\n",
    "2. **Mapping to pixels** (distorted):\n",
    "\n",
    "   $\n",
    "   \\begin{aligned}\n",
    "   u &= f_x \\, x'' + c_x, \\\\\n",
    "   v &= f_y \\, y'' + c_y.\n",
    "   \\end{aligned}\n",
    "   $\n",
    "\n",
    "4. **Inverse Distortion / Undistortion**:  \n",
    "   Given $(u, v)$, first find distorted normalized coordinates:\n",
    "\n",
    "   $\n",
    "   x'' = \\frac{u - c_x}{f_x}, \\quad\n",
    "   y'' = \\frac{v - c_y}{f_y}.\n",
    "   $\n",
    "\n",
    "   Then solve iteratively for $(x', y')$ such that the forward distortion equations above yield $(x'', y'')$. Finally map $(x', y')$ to undistorted pixel coordinates if needed:\n",
    "\n",
    "   $\n",
    "   u_{\\text{undistorted}} = f_x \\, x' + c_x, \n",
    "   \\quad\n",
    "   v_{\\text{undistorted}} = f_y \\, y' + c_y.\n",
    "   $\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Notes\n",
    "\n",
    "- In OpenCV, functions like **`cv::undistortPoints`** (C++), **`cv2.undistortPoints`** (Python), and **`cv::initUndistortRectifyMap`** handle the iterative/inversion steps.  \n",
    "- The same distortion model can be extended with additional parameters (e.g., $k_4, k_5, k_6$ in the rational polynomial model), but the principle remains the same.  \n",
    "- Undistortion typically re-maps the entire image so that straight lines in the scene appear straight in the image (removing curved distortions near the edges).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24dd6ff-33f4-467b-a82d-fc04a9c79fcc",
   "metadata": {},
   "source": [
    "OpenCV uses a **numerical iterative approach** for undistortion. Specifically, it iteratively solves for the undistorted normalized coordinates $(x', y')$ from the distorted normalized coordinates $(x'', y'')$. \n",
    "\n",
    "Here’s how OpenCV handles **undistortion** in detail:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Undistortion Workflow in OpenCV**\n",
    "\n",
    "When you call an OpenCV function for undistortion (e.g., `cv::undistort`, `cv::initUndistortRectifyMap`, or `cv::undistortPoints`), the process is as follows:\n",
    "\n",
    "1. **Normalize distorted pixel coordinates**: Convert the input pixel coordinates $(u, v)$ into distorted normalized coordinates $(x'', y'')$ using the intrinsic camera matrix:\n",
    "\n",
    "   $\n",
    "   x'' = \\frac{u - c_x}{f_x}, \\quad y'' = \\frac{v - c_y}{f_y}.\n",
    "   $\n",
    "\n",
    "2. **Iterative solution for undistortion**: Iteratively solve the nonlinear distortion equations to recover $(x', y')$, the undistorted normalized coordinates.\n",
    "\n",
    "3. **Reproject undistorted normalized coordinates**: Once $(x', y')$ is found, it is reprojected back into the pixel space using the intrinsic matrix (without distortion):\n",
    "\n",
    "   $\n",
    "   u_{\\text{undistorted}} = f_x \\cdot x' + c_x, \\quad v_{\\text{undistorted}} = f_y \\cdot y' + c_y.\n",
    "   $\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Iterative Approach in OpenCV**\n",
    "\n",
    "The nonlinear distortion equations:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "x'' &= x' \\cdot (1 + k_1 \\, r^2 + k_2 \\, r^4 + k_3 \\, r^6) \n",
    "       + 2 \\, p_1 \\, x' \\, y' + p_2 \\, (r^2 + 2 {x'}^2), \\\\\n",
    "y'' &= y' \\cdot (1 + k_1 \\, r^2 + k_2 \\, r^4 + k_3 \\, r^6) \n",
    "       + p_1 \\, (r^2 + 2 {y'}^2) + 2 \\, p_2 \\, x' \\, y',\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "are solved iteratively for $(x', y')$. OpenCV typically uses a fixed-point iteration method:\n",
    "\n",
    "1. **Initialization**: Start with an initial guess:\n",
    "   $\n",
    "   \\hat{x}' = x'', \\quad \\hat{y}' = y''.\n",
    "   $\n",
    "\n",
    "2. **Iterative refinement**: At each iteration, compute:\n",
    "   $\n",
    "   r^2 = \\hat{x}'^2 + \\hat{y}'^2,\n",
    "   $\n",
    "   and update the scale factor and tangential corrections:\n",
    "   $\n",
    "   \\hat{x}' = \\frac{x'' - 2 p_1 \\hat{x}' \\hat{y}' - p_2 (r^2 + 2 \\hat{x}'^2)}{1 + k_1 r^2 + k_2 r^4 + k_3 r^6},\n",
    "   $\n",
    "   $\n",
    "   \\hat{y}' = \\frac{y'' - p_1 (r^2 + 2 \\hat{y}'^2) - 2 p_2 \\hat{x}' \\hat{y}'}{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}.\n",
    "   $\n",
    "\n",
    "3. **Convergence**: Repeat until the change in $(\\hat{x}', \\hat{y}')$ between iterations is below a threshold (e.g., $10^{-6}$) or a maximum number of iterations is reached.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Why Iterative Instead of Polynomial Approximation?**\n",
    "\n",
    "- **Iterative methods** provide more accurate results for complex distortion models, especially when the distortions are large.\n",
    "- Polynomial approximation methods are faster but less precise, especially for high-order distortions. OpenCV prioritizes accuracy for undistortion and thus uses iterative refinement.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Precomputed Maps for Efficiency**\n",
    "\n",
    "For applications requiring repeated undistortion (e.g., video processing), OpenCV can **precompute undistortion maps** using `cv::initUndistortRectifyMap`. This avoids solving the distortion equations for every pixel during runtime.\n",
    "\n",
    "- OpenCV creates lookup tables (maps) that directly map distorted pixel coordinates to undistorted coordinates. These maps are used with `cv::remap` to apply the undistortion efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Alternative Polynomial Approximation**\n",
    "\n",
    "While OpenCV itself doesn’t use polynomial approximations for undistortion, you could approximate the distortion correction using Taylor expansion or other analytical techniques. However, this approach sacrifices precision and may not work well for extreme distortions or fisheye lenses.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
